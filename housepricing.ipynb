{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "66752080",
   "metadata": {},
   "source": [
    "# HOUSE PRICES: Advanced regression techniques\n",
    "\n",
    "Join the Kaggle competition titled: “House Prices - Advanced Regression Techniques” (https://www.kaggle.com/competitions/house-prices-advanced-regression-techniques/data?select=test.csv) \n",
    "We aim to predict the sales price of the houses based on the features given in the data set.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "cd002b93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the librairies\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as lt\n",
    "import seaborn as sns\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31dd8116",
   "metadata": {},
   "source": [
    "## Data preprocessing: Training data\n",
    "* Cleaning the data\n",
    "* Feature engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "16090b53",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>MSSubClass</th>\n",
       "      <th>MSZoning</th>\n",
       "      <th>LotFrontage</th>\n",
       "      <th>LotArea</th>\n",
       "      <th>Street</th>\n",
       "      <th>Alley</th>\n",
       "      <th>LotShape</th>\n",
       "      <th>LandContour</th>\n",
       "      <th>Utilities</th>\n",
       "      <th>...</th>\n",
       "      <th>PoolArea</th>\n",
       "      <th>PoolQC</th>\n",
       "      <th>Fence</th>\n",
       "      <th>MiscFeature</th>\n",
       "      <th>MiscVal</th>\n",
       "      <th>MoSold</th>\n",
       "      <th>YrSold</th>\n",
       "      <th>SaleType</th>\n",
       "      <th>SaleCondition</th>\n",
       "      <th>SalePrice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>65.0</td>\n",
       "      <td>8450</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>208500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>80.0</td>\n",
       "      <td>9600</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2007</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>181500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>68.0</td>\n",
       "      <td>11250</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>223500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>70</td>\n",
       "      <td>RL</td>\n",
       "      <td>60.0</td>\n",
       "      <td>9550</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2006</td>\n",
       "      <td>WD</td>\n",
       "      <td>Abnorml</td>\n",
       "      <td>140000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>84.0</td>\n",
       "      <td>14260</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>250000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 81 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id  MSSubClass MSZoning  LotFrontage  LotArea Street Alley LotShape  \\\n",
       "0   1          60       RL         65.0     8450   Pave   NaN      Reg   \n",
       "1   2          20       RL         80.0     9600   Pave   NaN      Reg   \n",
       "2   3          60       RL         68.0    11250   Pave   NaN      IR1   \n",
       "3   4          70       RL         60.0     9550   Pave   NaN      IR1   \n",
       "4   5          60       RL         84.0    14260   Pave   NaN      IR1   \n",
       "\n",
       "  LandContour Utilities  ... PoolArea PoolQC Fence MiscFeature MiscVal MoSold  \\\n",
       "0         Lvl    AllPub  ...        0    NaN   NaN         NaN       0      2   \n",
       "1         Lvl    AllPub  ...        0    NaN   NaN         NaN       0      5   \n",
       "2         Lvl    AllPub  ...        0    NaN   NaN         NaN       0      9   \n",
       "3         Lvl    AllPub  ...        0    NaN   NaN         NaN       0      2   \n",
       "4         Lvl    AllPub  ...        0    NaN   NaN         NaN       0     12   \n",
       "\n",
       "  YrSold  SaleType  SaleCondition  SalePrice  \n",
       "0   2008        WD         Normal     208500  \n",
       "1   2007        WD         Normal     181500  \n",
       "2   2008        WD         Normal     223500  \n",
       "3   2006        WD        Abnorml     140000  \n",
       "4   2008        WD         Normal     250000  \n",
       "\n",
       "[5 rows x 81 columns]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.read_csv('train.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "e616bc43",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1460, 81)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "fb6f6de7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1460 entries, 0 to 1459\n",
      "Data columns (total 81 columns):\n",
      " #   Column         Non-Null Count  Dtype  \n",
      "---  ------         --------------  -----  \n",
      " 0   Id             1460 non-null   int64  \n",
      " 1   MSSubClass     1460 non-null   int64  \n",
      " 2   MSZoning       1460 non-null   object \n",
      " 3   LotFrontage    1201 non-null   float64\n",
      " 4   LotArea        1460 non-null   int64  \n",
      " 5   Street         1460 non-null   object \n",
      " 6   Alley          91 non-null     object \n",
      " 7   LotShape       1460 non-null   object \n",
      " 8   LandContour    1460 non-null   object \n",
      " 9   Utilities      1460 non-null   object \n",
      " 10  LotConfig      1460 non-null   object \n",
      " 11  LandSlope      1460 non-null   object \n",
      " 12  Neighborhood   1460 non-null   object \n",
      " 13  Condition1     1460 non-null   object \n",
      " 14  Condition2     1460 non-null   object \n",
      " 15  BldgType       1460 non-null   object \n",
      " 16  HouseStyle     1460 non-null   object \n",
      " 17  OverallQual    1460 non-null   int64  \n",
      " 18  OverallCond    1460 non-null   int64  \n",
      " 19  YearBuilt      1460 non-null   int64  \n",
      " 20  YearRemodAdd   1460 non-null   int64  \n",
      " 21  RoofStyle      1460 non-null   object \n",
      " 22  RoofMatl       1460 non-null   object \n",
      " 23  Exterior1st    1460 non-null   object \n",
      " 24  Exterior2nd    1460 non-null   object \n",
      " 25  MasVnrType     1452 non-null   object \n",
      " 26  MasVnrArea     1452 non-null   float64\n",
      " 27  ExterQual      1460 non-null   object \n",
      " 28  ExterCond      1460 non-null   object \n",
      " 29  Foundation     1460 non-null   object \n",
      " 30  BsmtQual       1423 non-null   object \n",
      " 31  BsmtCond       1423 non-null   object \n",
      " 32  BsmtExposure   1422 non-null   object \n",
      " 33  BsmtFinType1   1423 non-null   object \n",
      " 34  BsmtFinSF1     1460 non-null   int64  \n",
      " 35  BsmtFinType2   1422 non-null   object \n",
      " 36  BsmtFinSF2     1460 non-null   int64  \n",
      " 37  BsmtUnfSF      1460 non-null   int64  \n",
      " 38  TotalBsmtSF    1460 non-null   int64  \n",
      " 39  Heating        1460 non-null   object \n",
      " 40  HeatingQC      1460 non-null   object \n",
      " 41  CentralAir     1460 non-null   object \n",
      " 42  Electrical     1459 non-null   object \n",
      " 43  1stFlrSF       1460 non-null   int64  \n",
      " 44  2ndFlrSF       1460 non-null   int64  \n",
      " 45  LowQualFinSF   1460 non-null   int64  \n",
      " 46  GrLivArea      1460 non-null   int64  \n",
      " 47  BsmtFullBath   1460 non-null   int64  \n",
      " 48  BsmtHalfBath   1460 non-null   int64  \n",
      " 49  FullBath       1460 non-null   int64  \n",
      " 50  HalfBath       1460 non-null   int64  \n",
      " 51  BedroomAbvGr   1460 non-null   int64  \n",
      " 52  KitchenAbvGr   1460 non-null   int64  \n",
      " 53  KitchenQual    1460 non-null   object \n",
      " 54  TotRmsAbvGrd   1460 non-null   int64  \n",
      " 55  Functional     1460 non-null   object \n",
      " 56  Fireplaces     1460 non-null   int64  \n",
      " 57  FireplaceQu    770 non-null    object \n",
      " 58  GarageType     1379 non-null   object \n",
      " 59  GarageYrBlt    1379 non-null   float64\n",
      " 60  GarageFinish   1379 non-null   object \n",
      " 61  GarageCars     1460 non-null   int64  \n",
      " 62  GarageArea     1460 non-null   int64  \n",
      " 63  GarageQual     1379 non-null   object \n",
      " 64  GarageCond     1379 non-null   object \n",
      " 65  PavedDrive     1460 non-null   object \n",
      " 66  WoodDeckSF     1460 non-null   int64  \n",
      " 67  OpenPorchSF    1460 non-null   int64  \n",
      " 68  EnclosedPorch  1460 non-null   int64  \n",
      " 69  3SsnPorch      1460 non-null   int64  \n",
      " 70  ScreenPorch    1460 non-null   int64  \n",
      " 71  PoolArea       1460 non-null   int64  \n",
      " 72  PoolQC         7 non-null      object \n",
      " 73  Fence          281 non-null    object \n",
      " 74  MiscFeature    54 non-null     object \n",
      " 75  MiscVal        1460 non-null   int64  \n",
      " 76  MoSold         1460 non-null   int64  \n",
      " 77  YrSold         1460 non-null   int64  \n",
      " 78  SaleType       1460 non-null   object \n",
      " 79  SaleCondition  1460 non-null   object \n",
      " 80  SalePrice      1460 non-null   int64  \n",
      "dtypes: float64(3), int64(35), object(43)\n",
      "memory usage: 924.0+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "b50eea4a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Id                 0\n",
       "MSSubClass         0\n",
       "MSZoning           0\n",
       "LotFrontage      259\n",
       "LotArea            0\n",
       "                ... \n",
       "MoSold             0\n",
       "YrSold             0\n",
       "SaleType           0\n",
       "SaleCondition      0\n",
       "SalePrice          0\n",
       "Length: 81, dtype: int64"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# To check the sum of missing values for each features\n",
    "# Features with lots of missing values will be dropped\n",
    "# Consider also domain expert knowledge\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "b8961998",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# To check the missing values of the features\n",
    "# From the heatmap we cn sea that PoolQc, MoSold and other have high missing values\n",
    "sns.heatmap(df.isnull(),yticklabels='False',cbar='False')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "51377b37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filling the missing values: Replacng values by their mean or objects by their modes (most frequent categories)\n",
    "df['LotFrontage']=df['LotFrontage'].fillna(df['LotFrontage'].mean())\n",
    "df['MasVnrType']=df['MasVnrType'].fillna(df['MasVnrType'].mode([0]))\n",
    "df['MasVnrArea']=df['MasVnrArea'].fillna(df['MasVnrArea'].mean())\n",
    "df['BsmtQual']=df['BsmtQual'].fillna(df['BsmtQual'].mode([0]))\n",
    "df['BsmtCond']=df['BsmtCond'].fillna(df['BsmtCond'].mode([0]))\n",
    "df['BsmtExposure']=df['BsmtExposure'].fillna(df['BsmtExposure'].mode([0]))\n",
    "df['BsmtFinType1']=df['BsmtFinType1'].fillna(df['BsmtFinType1'].mode([0]))\n",
    "df['BsmtFinType2']=df['BsmtFinType2'].fillna(df['BsmtFinType2'].mode([0]))\n",
    "df['Electrical']=df['Electrical'].fillna(df['Electrical'].mode([0]))\n",
    "df['GarageType']=df['GarageType'].fillna(df['GarageType'].mode([0]))\n",
    "df['GarageYrBlt']=df['GarageYrBlt'].fillna(df['GarageYrBlt'].mean())\n",
    "df['GarageFinish']=df['GarageFinish'].fillna(df['GarageFinish'].mode([0]))\n",
    "df['GarageQual']=df['GarageQual'].fillna(df['GarageQual'].mode([0]))\n",
    "df['GarageCond']=df['GarageCond'].fillna(df['GarageCond'].mode([0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "45f82fd4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1460, 75)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dropping some entries: perform for features with at leat 50% null values\n",
    "df.drop(['Alley','FireplaceQu','PoolQC','Fence','MiscFeature','Id'],axis=1,inplace=True)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "6c2a98b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Observed the clean data\n",
    "sns.heatmap(df.isnull(),yticklabels='False',cbar='False',cmap='coolwarm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "072053d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1460, 75)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#df.dropna(inplace=True)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "bea8db84",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MSSubClass</th>\n",
       "      <th>MSZoning</th>\n",
       "      <th>LotFrontage</th>\n",
       "      <th>LotArea</th>\n",
       "      <th>Street</th>\n",
       "      <th>LotShape</th>\n",
       "      <th>LandContour</th>\n",
       "      <th>Utilities</th>\n",
       "      <th>LotConfig</th>\n",
       "      <th>LandSlope</th>\n",
       "      <th>...</th>\n",
       "      <th>EnclosedPorch</th>\n",
       "      <th>3SsnPorch</th>\n",
       "      <th>ScreenPorch</th>\n",
       "      <th>PoolArea</th>\n",
       "      <th>MiscVal</th>\n",
       "      <th>MoSold</th>\n",
       "      <th>YrSold</th>\n",
       "      <th>SaleType</th>\n",
       "      <th>SaleCondition</th>\n",
       "      <th>SalePrice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>65.0</td>\n",
       "      <td>8450</td>\n",
       "      <td>Pave</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Inside</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>208500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>80.0</td>\n",
       "      <td>9600</td>\n",
       "      <td>Pave</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>FR2</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2007</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>181500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>68.0</td>\n",
       "      <td>11250</td>\n",
       "      <td>Pave</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Inside</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>223500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>70</td>\n",
       "      <td>RL</td>\n",
       "      <td>60.0</td>\n",
       "      <td>9550</td>\n",
       "      <td>Pave</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Corner</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>...</td>\n",
       "      <td>272</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2006</td>\n",
       "      <td>WD</td>\n",
       "      <td>Abnorml</td>\n",
       "      <td>140000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>84.0</td>\n",
       "      <td>14260</td>\n",
       "      <td>Pave</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>FR2</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>250000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 75 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   MSSubClass MSZoning  LotFrontage  LotArea Street LotShape LandContour  \\\n",
       "0          60       RL         65.0     8450   Pave      Reg         Lvl   \n",
       "1          20       RL         80.0     9600   Pave      Reg         Lvl   \n",
       "2          60       RL         68.0    11250   Pave      IR1         Lvl   \n",
       "3          70       RL         60.0     9550   Pave      IR1         Lvl   \n",
       "4          60       RL         84.0    14260   Pave      IR1         Lvl   \n",
       "\n",
       "  Utilities LotConfig LandSlope  ... EnclosedPorch 3SsnPorch ScreenPorch  \\\n",
       "0    AllPub    Inside       Gtl  ...             0         0           0   \n",
       "1    AllPub       FR2       Gtl  ...             0         0           0   \n",
       "2    AllPub    Inside       Gtl  ...             0         0           0   \n",
       "3    AllPub    Corner       Gtl  ...           272         0           0   \n",
       "4    AllPub       FR2       Gtl  ...             0         0           0   \n",
       "\n",
       "  PoolArea MiscVal  MoSold  YrSold  SaleType  SaleCondition SalePrice  \n",
       "0        0       0       2    2008        WD         Normal    208500  \n",
       "1        0       0       5    2007        WD         Normal    181500  \n",
       "2        0       0       9    2008        WD         Normal    223500  \n",
       "3        0       0       2    2006        WD        Abnorml    140000  \n",
       "4        0       0      12    2008        WD         Normal    250000  \n",
       "\n",
       "[5 rows x 75 columns]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "e9929405",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee13ebd6",
   "metadata": {},
   "source": [
    "## Import cleantest.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "38327e45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MSSubClass</th>\n",
       "      <th>MSZoning</th>\n",
       "      <th>LotFrontage</th>\n",
       "      <th>LotArea</th>\n",
       "      <th>Street</th>\n",
       "      <th>LotShape</th>\n",
       "      <th>LandContour</th>\n",
       "      <th>Utilities</th>\n",
       "      <th>LotConfig</th>\n",
       "      <th>LandSlope</th>\n",
       "      <th>...</th>\n",
       "      <th>OpenPorchSF</th>\n",
       "      <th>EnclosedPorch</th>\n",
       "      <th>3SsnPorch</th>\n",
       "      <th>ScreenPorch</th>\n",
       "      <th>PoolArea</th>\n",
       "      <th>MiscVal</th>\n",
       "      <th>MoSold</th>\n",
       "      <th>YrSold</th>\n",
       "      <th>SaleType</th>\n",
       "      <th>SaleCondition</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20</td>\n",
       "      <td>RH</td>\n",
       "      <td>80.0</td>\n",
       "      <td>11622</td>\n",
       "      <td>Pave</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Inside</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>120</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>2010</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>81.0</td>\n",
       "      <td>14267</td>\n",
       "      <td>Pave</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Corner</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>...</td>\n",
       "      <td>36</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12500</td>\n",
       "      <td>6</td>\n",
       "      <td>2010</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>74.0</td>\n",
       "      <td>13830</td>\n",
       "      <td>Pave</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Inside</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>...</td>\n",
       "      <td>34</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2010</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>78.0</td>\n",
       "      <td>9978</td>\n",
       "      <td>Pave</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Inside</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>...</td>\n",
       "      <td>36</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>2010</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>120</td>\n",
       "      <td>RL</td>\n",
       "      <td>43.0</td>\n",
       "      <td>5005</td>\n",
       "      <td>Pave</td>\n",
       "      <td>IR1</td>\n",
       "      <td>HLS</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Inside</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>...</td>\n",
       "      <td>82</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>144</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2010</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 74 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   MSSubClass MSZoning  LotFrontage  LotArea Street LotShape LandContour  \\\n",
       "0          20       RH         80.0    11622   Pave      Reg         Lvl   \n",
       "1          20       RL         81.0    14267   Pave      IR1         Lvl   \n",
       "2          60       RL         74.0    13830   Pave      IR1         Lvl   \n",
       "3          60       RL         78.0     9978   Pave      IR1         Lvl   \n",
       "4         120       RL         43.0     5005   Pave      IR1         HLS   \n",
       "\n",
       "  Utilities LotConfig LandSlope  ... OpenPorchSF EnclosedPorch 3SsnPorch  \\\n",
       "0    AllPub    Inside       Gtl  ...           0             0         0   \n",
       "1    AllPub    Corner       Gtl  ...          36             0         0   \n",
       "2    AllPub    Inside       Gtl  ...          34             0         0   \n",
       "3    AllPub    Inside       Gtl  ...          36             0         0   \n",
       "4    AllPub    Inside       Gtl  ...          82             0         0   \n",
       "\n",
       "  ScreenPorch PoolArea  MiscVal  MoSold  YrSold  SaleType SaleCondition  \n",
       "0         120        0        0       6    2010        WD        Normal  \n",
       "1           0        0    12500       6    2010        WD        Normal  \n",
       "2           0        0        0       3    2010        WD        Normal  \n",
       "3           0        0        0       6    2010        WD        Normal  \n",
       "4         144        0        0       1    2010        WD        Normal  \n",
       "\n",
       "[5 rows x 74 columns]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df=pd.read_csv('cleantest.csv')\n",
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "4e00b72a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate the training set and cleantest set into one whole data set\n",
    "data_df=pd.concat([df,test_df],axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "0e1d8f39",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2919, 75)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "b274e417",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Isolate all the categorigal features in the data set to peform one hot encoding\n",
    "columns=['MSZoning','Street','LotShape','LandContour','Utilities','LotConfig','LandSlope','Neighborhood','Condition1','Condition2',\n",
    "            'BldgType','HouseStyle','RoofStyle','RoofMatl','Exterior1st','Exterior2nd','MasVnrType','ExterQual','ExterCond',\n",
    "            'Foundation','BsmtQual','BsmtCond','BsmtExposure','BsmtFinType1','BsmtFinType2','Heating','HeatingQC',\n",
    "            'CentralAir','Electrical','KitchenQual','Functional','GarageType','GarageFinish','GarageQual','GarageCond',\n",
    "            'PavedDrive','SaleType','SaleCondition']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "00030694",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MSSubClass</th>\n",
       "      <th>LotFrontage</th>\n",
       "      <th>LotArea</th>\n",
       "      <th>OverallQual</th>\n",
       "      <th>OverallCond</th>\n",
       "      <th>YearBuilt</th>\n",
       "      <th>YearRemodAdd</th>\n",
       "      <th>MasVnrArea</th>\n",
       "      <th>BsmtFinSF1</th>\n",
       "      <th>BsmtFinSF2</th>\n",
       "      <th>...</th>\n",
       "      <th>SaleType_ConLw</th>\n",
       "      <th>SaleType_New</th>\n",
       "      <th>SaleType_Oth</th>\n",
       "      <th>SaleType_WD</th>\n",
       "      <th>SaleCondition_Abnorml</th>\n",
       "      <th>SaleCondition_AdjLand</th>\n",
       "      <th>SaleCondition_Alloca</th>\n",
       "      <th>SaleCondition_Family</th>\n",
       "      <th>SaleCondition_Normal</th>\n",
       "      <th>SaleCondition_Partial</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>60</td>\n",
       "      <td>65.0</td>\n",
       "      <td>8450</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>2003</td>\n",
       "      <td>2003</td>\n",
       "      <td>196.0</td>\n",
       "      <td>706.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20</td>\n",
       "      <td>80.0</td>\n",
       "      <td>9600</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>1976</td>\n",
       "      <td>1976</td>\n",
       "      <td>0.0</td>\n",
       "      <td>978.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>60</td>\n",
       "      <td>68.0</td>\n",
       "      <td>11250</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>2001</td>\n",
       "      <td>2002</td>\n",
       "      <td>162.0</td>\n",
       "      <td>486.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>70</td>\n",
       "      <td>60.0</td>\n",
       "      <td>9550</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>1915</td>\n",
       "      <td>1970</td>\n",
       "      <td>0.0</td>\n",
       "      <td>216.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>60</td>\n",
       "      <td>84.0</td>\n",
       "      <td>14260</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>2000</td>\n",
       "      <td>2000</td>\n",
       "      <td>350.0</td>\n",
       "      <td>655.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 271 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   MSSubClass  LotFrontage  LotArea  OverallQual  OverallCond  YearBuilt  \\\n",
       "0          60         65.0     8450            7            5       2003   \n",
       "1          20         80.0     9600            6            8       1976   \n",
       "2          60         68.0    11250            7            5       2001   \n",
       "3          70         60.0     9550            7            5       1915   \n",
       "4          60         84.0    14260            8            5       2000   \n",
       "\n",
       "   YearRemodAdd  MasVnrArea  BsmtFinSF1  BsmtFinSF2  ...  SaleType_ConLw  \\\n",
       "0          2003       196.0       706.0         0.0  ...               0   \n",
       "1          1976         0.0       978.0         0.0  ...               0   \n",
       "2          2002       162.0       486.0         0.0  ...               0   \n",
       "3          1970         0.0       216.0         0.0  ...               0   \n",
       "4          2000       350.0       655.0         0.0  ...               0   \n",
       "\n",
       "   SaleType_New  SaleType_Oth  SaleType_WD  SaleCondition_Abnorml  \\\n",
       "0             0             0            1                      0   \n",
       "1             0             0            1                      0   \n",
       "2             0             0            1                      0   \n",
       "3             0             0            1                      1   \n",
       "4             0             0            1                      0   \n",
       "\n",
       "   SaleCondition_AdjLand  SaleCondition_Alloca  SaleCondition_Family  \\\n",
       "0                      0                     0                     0   \n",
       "1                      0                     0                     0   \n",
       "2                      0                     0                     0   \n",
       "3                      0                     0                     0   \n",
       "4                      0                     0                     0   \n",
       "\n",
       "   SaleCondition_Normal  SaleCondition_Partial  \n",
       "0                     1                      0  \n",
       "1                     1                      0  \n",
       "2                     1                      0  \n",
       "3                     0                      0  \n",
       "4                     1                      0  \n",
       "\n",
       "[5 rows x 271 columns]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# one hot encoding\n",
    "one_hot_encoded_data = pd.get_dummies(data_df, columns) \n",
    "one_hot_encoded_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "9e1d96a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2919, 271)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "one_hot_encoded_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "425d6d52",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df=one_hot_encoded_data.loc[:,~one_hot_encoded_data.columns.duplicated()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "db0f385b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2919, 271)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "one_hot_encoded_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "b8ce5e2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Devide the final_df into train and test\n",
    "df_Train=final_df.iloc[:1459,:]\n",
    "df_Test=final_df.iloc[:1459,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "5649c0ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\amankou anicet\\AppData\\Local\\Temp\\ipykernel_25480\\3985304647.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_Test.drop(['SalePrice'],axis=1,inplace=True)\n"
     ]
    }
   ],
   "source": [
    "df_Test.drop(['SalePrice'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "14768076",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the y_train and x_train\n",
    "x_train=df_Train.drop(['SalePrice'],axis=1)\n",
    "y_train=df_Train['SalePrice']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "26bd35a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
       "             colsample_bylevel=None, colsample_bynode=None,\n",
       "             colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
       "             enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "             gamma=None, grow_policy=None, importance_type=None,\n",
       "             interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "             max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "             max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "             multi_strategy=None, n_estimators=None, n_jobs=None,\n",
       "             num_parallel_tree=None, random_state=None, ...)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from xgboost import XGBRegressor\n",
    "from sklearn.metrics import accuracy_score\n",
    "model_=XGBRegressor()\n",
    "model_.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "c00381ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "filename='final_model.pkl'\n",
    "pickle.dump(model_,open(filename,'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "96841922",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred= model_.predict(df_Test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "c6467fbd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([206668.78, 181397.67, 221602.7 , ..., 206982.06, 267375.28,\n",
       "       141967.03], dtype=float32)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "a06de635",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred=pd.DataFrame(y_pred)\n",
    "sub_df=pd.read_csv('sample_submission.csv')\n",
    "datasets=pd.concat([sub_df['Id'],pred],axis=1)\n",
    "datasets.columns=['Id','SalePrice']\n",
    "datasets.to_csv('sample_submission2.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "0bf766f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LeakyReLU,PReLU,ELU\n",
    "from keras.layers import Dropout\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "64c07c57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1500\n",
      "117/117 [==============================] - 1s 2ms/step - loss: 36095909888.0000 - val_loss: 31754485760.0000\n",
      "Epoch 2/1500\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 18876540928.0000 - val_loss: 8041165824.0000\n",
      "Epoch 3/1500\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 8441314304.0000 - val_loss: 5951518208.0000\n",
      "Epoch 4/1500\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 7583610880.0000 - val_loss: 5757127680.0000\n",
      "Epoch 5/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 7171104256.0000 - val_loss: 5594067456.0000\n",
      "Epoch 6/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 6847462912.0000 - val_loss: 5495401472.0000\n",
      "Epoch 7/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 6597135872.0000 - val_loss: 5409136128.0000\n",
      "Epoch 8/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 6325801984.0000 - val_loss: 5317660672.0000\n",
      "Epoch 9/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 6108770304.0000 - val_loss: 5229441536.0000\n",
      "Epoch 10/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 5906632704.0000 - val_loss: 5157283840.0000\n",
      "Epoch 11/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 5728153088.0000 - val_loss: 5082191360.0000\n",
      "Epoch 12/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 5558931968.0000 - val_loss: 5005389824.0000\n",
      "Epoch 13/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 5386076160.0000 - val_loss: 4936066048.0000\n",
      "Epoch 14/1500\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 5203970048.0000 - val_loss: 4857890816.0000\n",
      "Epoch 15/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 5001335296.0000 - val_loss: 4771842048.0000\n",
      "Epoch 16/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 4804505088.0000 - val_loss: 4673956352.0000\n",
      "Epoch 17/1500\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 4629159424.0000 - val_loss: 4593846784.0000\n",
      "Epoch 18/1500\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 4421914624.0000 - val_loss: 4519392768.0000\n",
      "Epoch 19/1500\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 4238516736.0000 - val_loss: 4436854272.0000\n",
      "Epoch 20/1500\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 4078630912.0000 - val_loss: 4354296320.0000\n",
      "Epoch 21/1500\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 3904495360.0000 - val_loss: 4268472832.0000\n",
      "Epoch 22/1500\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 3740799744.0000 - val_loss: 4193126144.0000\n",
      "Epoch 23/1500\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 3592753664.0000 - val_loss: 4120180992.0000\n",
      "Epoch 24/1500\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 3457054720.0000 - val_loss: 4058659840.0000\n",
      "Epoch 25/1500\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 3334185472.0000 - val_loss: 4005500672.0000\n",
      "Epoch 26/1500\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 3232971520.0000 - val_loss: 3930664448.0000\n",
      "Epoch 27/1500\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 3113822464.0000 - val_loss: 3858937088.0000\n",
      "Epoch 28/1500\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 3003488000.0000 - val_loss: 3801945856.0000\n",
      "Epoch 29/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 2889520128.0000 - val_loss: 3734766080.0000\n",
      "Epoch 30/1500\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 2772652544.0000 - val_loss: 3660468992.0000\n",
      "Epoch 31/1500\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 2672338688.0000 - val_loss: 3599224832.0000\n",
      "Epoch 32/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 2561956608.0000 - val_loss: 3543005440.0000\n",
      "Epoch 33/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 2472721408.0000 - val_loss: 3535078400.0000\n",
      "Epoch 34/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 2376675072.0000 - val_loss: 3442438144.0000\n",
      "Epoch 35/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 2278153472.0000 - val_loss: 3543414272.0000\n",
      "Epoch 36/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 2212295936.0000 - val_loss: 3397451008.0000\n",
      "Epoch 37/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 2117588224.0000 - val_loss: 3370674688.0000\n",
      "Epoch 38/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 2044211328.0000 - val_loss: 3314233088.0000\n",
      "Epoch 39/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 1964975232.0000 - val_loss: 3229943040.0000\n",
      "Epoch 40/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 1909624960.0000 - val_loss: 3257743872.0000\n",
      "Epoch 41/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 1853485824.0000 - val_loss: 3247860224.0000\n",
      "Epoch 42/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 1804510464.0000 - val_loss: 3392078848.0000\n",
      "Epoch 43/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 1756978560.0000 - val_loss: 3291570176.0000\n",
      "Epoch 44/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 1712204672.0000 - val_loss: 3287329536.0000\n",
      "Epoch 45/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 1681376640.0000 - val_loss: 3287615744.0000\n",
      "Epoch 46/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 1639648128.0000 - val_loss: 3407963904.0000\n",
      "Epoch 47/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 1626741120.0000 - val_loss: 3481266944.0000\n",
      "Epoch 48/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 1620804736.0000 - val_loss: 3485829632.0000\n",
      "Epoch 49/1500\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 1609083648.0000 - val_loss: 3505208064.0000\n",
      "Epoch 50/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 1588041216.0000 - val_loss: 3475227648.0000\n",
      "Epoch 51/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 1590950784.0000 - val_loss: 3501394688.0000\n",
      "Epoch 52/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 1579242624.0000 - val_loss: 3586990080.0000\n",
      "Epoch 53/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 1581688448.0000 - val_loss: 3515345664.0000\n",
      "Epoch 54/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 1567407872.0000 - val_loss: 3638174208.0000\n",
      "Epoch 55/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 1570540928.0000 - val_loss: 3610685952.0000\n",
      "Epoch 56/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 1556550528.0000 - val_loss: 3593332480.0000\n",
      "Epoch 57/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 1564359936.0000 - val_loss: 3671294208.0000\n",
      "Epoch 58/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 1551905792.0000 - val_loss: 3543255808.0000\n",
      "Epoch 59/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 1545212672.0000 - val_loss: 3656708352.0000\n",
      "Epoch 60/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 1553105920.0000 - val_loss: 3578209536.0000\n",
      "Epoch 61/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 1540658432.0000 - val_loss: 3609124864.0000\n",
      "Epoch 62/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 1545997440.0000 - val_loss: 3602616832.0000\n",
      "Epoch 63/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 1541958656.0000 - val_loss: 3591813888.0000\n",
      "Epoch 64/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 1545684736.0000 - val_loss: 3566556672.0000\n",
      "Epoch 65/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 1547059072.0000 - val_loss: 3589278208.0000\n",
      "Epoch 66/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 1536657152.0000 - val_loss: 3568915712.0000\n",
      "Epoch 67/1500\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 1536289152.0000 - val_loss: 3605063424.0000\n",
      "Epoch 68/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 1541176192.0000 - val_loss: 3588184320.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 69/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 1554988288.0000 - val_loss: 3652160768.0000\n",
      "Epoch 70/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 1531523840.0000 - val_loss: 3603024128.0000\n",
      "Epoch 71/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 1533301632.0000 - val_loss: 3554979328.0000\n",
      "Epoch 72/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 1539530752.0000 - val_loss: 3659456000.0000\n",
      "Epoch 73/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 1531696640.0000 - val_loss: 3557751040.0000\n",
      "Epoch 74/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 1542973056.0000 - val_loss: 3669411328.0000\n",
      "Epoch 75/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 1526779904.0000 - val_loss: 3591504640.0000\n",
      "Epoch 76/1500\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 1529653376.0000 - val_loss: 3563977216.0000\n",
      "Epoch 77/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 1540203136.0000 - val_loss: 3598841088.0000\n",
      "Epoch 78/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 1531255936.0000 - val_loss: 3640600320.0000\n",
      "Epoch 79/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 1530365952.0000 - val_loss: 3620820736.0000\n",
      "Epoch 80/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 1530214272.0000 - val_loss: 3725667584.0000\n",
      "Epoch 81/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 1538897024.0000 - val_loss: 3616340480.0000\n",
      "Epoch 82/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 1519295360.0000 - val_loss: 3591924480.0000\n",
      "Epoch 83/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 1517139328.0000 - val_loss: 3699920640.0000\n",
      "Epoch 84/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 1522111872.0000 - val_loss: 3656856320.0000\n",
      "Epoch 85/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 1519958144.0000 - val_loss: 3646203648.0000\n",
      "Epoch 86/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 1516496384.0000 - val_loss: 3610363392.0000\n",
      "Epoch 87/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 1509636480.0000 - val_loss: 3672305920.0000\n",
      "Epoch 88/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 1517026304.0000 - val_loss: 3542398208.0000\n",
      "Epoch 89/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 1518798976.0000 - val_loss: 3621496576.0000\n",
      "Epoch 90/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 1506682752.0000 - val_loss: 3731076608.0000\n",
      "Epoch 91/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 1507657344.0000 - val_loss: 3562291712.0000\n",
      "Epoch 92/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 1506284672.0000 - val_loss: 3645612288.0000\n",
      "Epoch 93/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 1504189184.0000 - val_loss: 3721540864.0000\n",
      "Epoch 94/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 1507795584.0000 - val_loss: 3601268224.0000\n",
      "Epoch 95/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 1499381248.0000 - val_loss: 3594603008.0000\n",
      "Epoch 96/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 1500537344.0000 - val_loss: 3679736832.0000\n",
      "Epoch 97/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 1513398016.0000 - val_loss: 3596939008.0000\n",
      "Epoch 98/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 1498511488.0000 - val_loss: 3566286080.0000\n",
      "Epoch 99/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 1508379648.0000 - val_loss: 3637637376.0000\n",
      "Epoch 100/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 1504304128.0000 - val_loss: 3610856960.0000\n",
      "Epoch 101/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 1506358656.0000 - val_loss: 3683843328.0000\n",
      "Epoch 102/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 1500552704.0000 - val_loss: 3626973440.0000\n",
      "Epoch 103/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 1495650176.0000 - val_loss: 3681212160.0000\n",
      "Epoch 104/1500\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 1493719040.0000 - val_loss: 3631787008.0000\n",
      "Epoch 105/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 1485546368.0000 - val_loss: 3589153536.0000\n",
      "Epoch 106/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 1479433472.0000 - val_loss: 3727770112.0000\n",
      "Epoch 107/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 1492082816.0000 - val_loss: 3587588352.0000\n",
      "Epoch 108/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 1492402176.0000 - val_loss: 3621333504.0000\n",
      "Epoch 109/1500\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 1485165056.0000 - val_loss: 3716475136.0000\n",
      "Epoch 110/1500\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 1482649472.0000 - val_loss: 3744149248.0000\n",
      "Epoch 111/1500\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 1482126720.0000 - val_loss: 3535944704.0000\n",
      "Epoch 112/1500\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 1485627392.0000 - val_loss: 3636751360.0000\n",
      "Epoch 113/1500\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 1481863168.0000 - val_loss: 3598626048.0000\n",
      "Epoch 114/1500\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 1484104832.0000 - val_loss: 3677240832.0000\n",
      "Epoch 115/1500\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 1488628224.0000 - val_loss: 3640237056.0000\n",
      "Epoch 116/1500\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 1475632896.0000 - val_loss: 3703235072.0000\n",
      "Epoch 117/1500\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 1479393664.0000 - val_loss: 3608936448.0000\n",
      "Epoch 118/1500\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 1486229120.0000 - val_loss: 3626851328.0000\n",
      "Epoch 119/1500\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 1472682368.0000 - val_loss: 3692720896.0000\n",
      "Epoch 120/1500\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 1471616384.0000 - val_loss: 3597535488.0000\n",
      "Epoch 121/1500\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 1470765568.0000 - val_loss: 3593187584.0000\n",
      "Epoch 122/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 1468391552.0000 - val_loss: 3554186752.0000\n",
      "Epoch 123/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 1475273216.0000 - val_loss: 3611030784.0000\n",
      "Epoch 124/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 1469408256.0000 - val_loss: 3644509952.0000\n",
      "Epoch 125/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 1461597312.0000 - val_loss: 3580440320.0000\n",
      "Epoch 126/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 1462080896.0000 - val_loss: 3618716672.0000\n",
      "Epoch 127/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 1464581120.0000 - val_loss: 3557846784.0000\n",
      "Epoch 128/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 1465431680.0000 - val_loss: 3671064320.0000\n",
      "Epoch 129/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 1456697728.0000 - val_loss: 3599509248.0000\n",
      "Epoch 130/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 1445130752.0000 - val_loss: 3535952896.0000\n",
      "Epoch 131/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 1463550208.0000 - val_loss: 3594850560.0000\n",
      "Epoch 132/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 1448735232.0000 - val_loss: 3650956800.0000\n",
      "Epoch 133/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 1448275712.0000 - val_loss: 3570664960.0000\n",
      "Epoch 134/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 1445246080.0000 - val_loss: 3755010304.0000\n",
      "Epoch 135/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 1455711488.0000 - val_loss: 3627165696.0000\n",
      "Epoch 136/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "117/117 [==============================] - 0s 1ms/step - loss: 1439883392.0000 - val_loss: 3615168768.0000\n",
      "Epoch 137/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 1445332736.0000 - val_loss: 3647799808.0000\n",
      "Epoch 138/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 1436519040.0000 - val_loss: 3603090688.0000\n",
      "Epoch 139/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 1442853632.0000 - val_loss: 3576610048.0000\n",
      "Epoch 140/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 1432791808.0000 - val_loss: 3602892544.0000\n",
      "Epoch 141/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 1431591296.0000 - val_loss: 3699983360.0000\n",
      "Epoch 142/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 1434343040.0000 - val_loss: 3589551616.0000\n",
      "Epoch 143/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 1422535680.0000 - val_loss: 3558215936.0000\n",
      "Epoch 144/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 1438247040.0000 - val_loss: 3536028416.0000\n",
      "Epoch 145/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 1429388928.0000 - val_loss: 3587971072.0000\n",
      "Epoch 146/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 1423941888.0000 - val_loss: 3670729728.0000\n",
      "Epoch 147/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 1413584256.0000 - val_loss: 3557598208.0000\n",
      "Epoch 148/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 1425295488.0000 - val_loss: 3675744256.0000\n",
      "Epoch 149/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 1418214784.0000 - val_loss: 3591400448.0000\n",
      "Epoch 150/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 1423339392.0000 - val_loss: 3690375424.0000\n",
      "Epoch 151/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 1413455616.0000 - val_loss: 3594992896.0000\n",
      "Epoch 152/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 1410226688.0000 - val_loss: 3618701056.0000\n",
      "Epoch 153/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 1408511104.0000 - val_loss: 3602550016.0000\n",
      "Epoch 154/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 1410804352.0000 - val_loss: 3613421056.0000\n",
      "Epoch 155/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 1411182464.0000 - val_loss: 3571719424.0000\n",
      "Epoch 156/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 1407068544.0000 - val_loss: 3755763456.0000\n",
      "Epoch 157/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 1409443456.0000 - val_loss: 3624856320.0000\n",
      "Epoch 158/1500\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 1408033664.0000 - val_loss: 3563580928.0000\n",
      "Epoch 159/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 1401840384.0000 - val_loss: 3614577920.0000\n",
      "Epoch 160/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 1401950080.0000 - val_loss: 3621454848.0000\n",
      "Epoch 161/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 1402958592.0000 - val_loss: 3629506560.0000\n",
      "Epoch 162/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 1395899520.0000 - val_loss: 3640657920.0000\n",
      "Epoch 163/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 1393116416.0000 - val_loss: 3661180416.0000\n",
      "Epoch 164/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 1388113024.0000 - val_loss: 3587052032.0000\n",
      "Epoch 165/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 1386736128.0000 - val_loss: 3622121984.0000\n",
      "Epoch 166/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 1389043968.0000 - val_loss: 3646219008.0000\n",
      "Epoch 167/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 1387025664.0000 - val_loss: 3626938624.0000\n",
      "Epoch 168/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 1395382016.0000 - val_loss: 3650851840.0000\n",
      "Epoch 169/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 1387882752.0000 - val_loss: 3710930432.0000\n",
      "Epoch 170/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 1379043200.0000 - val_loss: 3600023040.0000\n",
      "Epoch 171/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 1378653952.0000 - val_loss: 3658590976.0000\n",
      "Epoch 172/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 1378041984.0000 - val_loss: 3657928960.0000\n",
      "Epoch 173/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 1374129024.0000 - val_loss: 3672386304.0000\n",
      "Epoch 174/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 1382747008.0000 - val_loss: 3732609536.0000\n",
      "Epoch 175/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 1377806720.0000 - val_loss: 3711352832.0000\n",
      "Epoch 176/1500\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 1366464640.0000 - val_loss: 3707661824.0000\n",
      "Epoch 177/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 1365256064.0000 - val_loss: 3835946496.0000\n",
      "Epoch 178/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 1366373632.0000 - val_loss: 3645337600.0000\n",
      "Epoch 179/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 1369711744.0000 - val_loss: 3739579392.0000\n",
      "Epoch 180/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 1367931136.0000 - val_loss: 3644213760.0000\n",
      "Epoch 181/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 1358436864.0000 - val_loss: 3665291520.0000\n",
      "Epoch 182/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 1374593152.0000 - val_loss: 3670873856.0000\n",
      "Epoch 183/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 1354444928.0000 - val_loss: 3633754112.0000\n",
      "Epoch 184/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 1353962368.0000 - val_loss: 3659060736.0000\n",
      "Epoch 185/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 1362493056.0000 - val_loss: 3649728512.0000\n",
      "Epoch 186/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 1352530560.0000 - val_loss: 3742321920.0000\n",
      "Epoch 187/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 1352208640.0000 - val_loss: 3652330496.0000\n",
      "Epoch 188/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 1352085504.0000 - val_loss: 3787983104.0000\n",
      "Epoch 189/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 1351843200.0000 - val_loss: 3644933120.0000\n",
      "Epoch 190/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 1341302656.0000 - val_loss: 3713359360.0000\n",
      "Epoch 191/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 1337952512.0000 - val_loss: 3659081472.0000\n",
      "Epoch 192/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 1336561152.0000 - val_loss: 3791264256.0000\n",
      "Epoch 193/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 1342682240.0000 - val_loss: 3746250752.0000\n",
      "Epoch 194/1500\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 1338852352.0000 - val_loss: 3659011072.0000\n",
      "Epoch 195/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 1338183040.0000 - val_loss: 3751069440.0000\n",
      "Epoch 196/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 1336945536.0000 - val_loss: 3642832128.0000\n",
      "Epoch 197/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 1341256576.0000 - val_loss: 3663364608.0000\n",
      "Epoch 198/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 1337968256.0000 - val_loss: 3732216064.0000\n",
      "Epoch 199/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 1333757056.0000 - val_loss: 3813490432.0000\n",
      "Epoch 200/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 1332722432.0000 - val_loss: 3705842688.0000\n",
      "Epoch 201/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 1332763776.0000 - val_loss: 3786085120.0000\n",
      "Epoch 202/1500\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 1322839680.0000 - val_loss: 3668193280.0000\n",
      "Epoch 203/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "117/117 [==============================] - 0s 2ms/step - loss: 1324533120.0000 - val_loss: 3694820352.0000\n",
      "Epoch 204/1500\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 1335769728.0000 - val_loss: 3699137536.0000\n",
      "Epoch 205/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 1320763264.0000 - val_loss: 3753932032.0000\n",
      "Epoch 206/1500\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 1319397632.0000 - val_loss: 3725957888.0000\n",
      "Epoch 207/1500\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 1304673024.0000 - val_loss: 3649479680.0000\n",
      "Epoch 208/1500\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 1317850112.0000 - val_loss: 3796382464.0000\n",
      "Epoch 209/1500\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 1313245312.0000 - val_loss: 3719833344.0000\n",
      "Epoch 210/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 1316210560.0000 - val_loss: 3851410688.0000\n",
      "Epoch 211/1500\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 1310953344.0000 - val_loss: 3756757248.0000\n",
      "Epoch 212/1500\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 1314446208.0000 - val_loss: 3731292416.0000\n",
      "Epoch 213/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 1307293184.0000 - val_loss: 3824922368.0000\n",
      "Epoch 214/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 1310936448.0000 - val_loss: 3774406400.0000\n",
      "Epoch 215/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 1303272320.0000 - val_loss: 3750224128.0000\n",
      "Epoch 216/1500\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 1299519360.0000 - val_loss: 3760245504.0000\n",
      "Epoch 217/1500\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 1302174464.0000 - val_loss: 3703193344.0000\n",
      "Epoch 218/1500\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 1296431744.0000 - val_loss: 3787238912.0000\n",
      "Epoch 219/1500\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 1304532224.0000 - val_loss: 3705513216.0000\n",
      "Epoch 220/1500\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 1293935616.0000 - val_loss: 3727000576.0000\n",
      "Epoch 221/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 1298190208.0000 - val_loss: 3691117568.0000\n",
      "Epoch 222/1500\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 1289742336.0000 - val_loss: 3759246080.0000\n",
      "Epoch 223/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 1297559424.0000 - val_loss: 3722757120.0000\n",
      "Epoch 224/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 1290636928.0000 - val_loss: 3763268608.0000\n",
      "Epoch 225/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 1288546816.0000 - val_loss: 3737456896.0000\n",
      "Epoch 226/1500\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 1294029440.0000 - val_loss: 3779864576.0000\n",
      "Epoch 227/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 1289385088.0000 - val_loss: 3792601088.0000\n",
      "Epoch 228/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 1288912128.0000 - val_loss: 3740072960.0000\n",
      "Epoch 229/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 1289655424.0000 - val_loss: 3678933248.0000\n",
      "Epoch 230/1500\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 1292391168.0000 - val_loss: 3738303744.0000\n",
      "Epoch 231/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 1283046144.0000 - val_loss: 3757327360.0000\n",
      "Epoch 232/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 1282440960.0000 - val_loss: 3729196032.0000\n",
      "Epoch 233/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 1280674688.0000 - val_loss: 3741940736.0000\n",
      "Epoch 234/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 1271527168.0000 - val_loss: 3844410368.0000\n",
      "Epoch 235/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 1279481216.0000 - val_loss: 3811916800.0000\n",
      "Epoch 236/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 1271203584.0000 - val_loss: 3830023424.0000\n",
      "Epoch 237/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 1272805504.0000 - val_loss: 3702698496.0000\n",
      "Epoch 238/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 1274077440.0000 - val_loss: 3796246528.0000\n",
      "Epoch 239/1500\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 1271122944.0000 - val_loss: 3669343744.0000\n",
      "Epoch 240/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 1271436288.0000 - val_loss: 3810495488.0000\n",
      "Epoch 241/1500\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 1268553728.0000 - val_loss: 3806254080.0000\n",
      "Epoch 242/1500\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 1269200896.0000 - val_loss: 3763869440.0000\n",
      "Epoch 243/1500\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 1267892224.0000 - val_loss: 3864196096.0000\n",
      "Epoch 244/1500\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 1269679616.0000 - val_loss: 3790961664.0000\n",
      "Epoch 245/1500\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 1262113920.0000 - val_loss: 3771514624.0000\n",
      "Epoch 246/1500\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 1262824192.0000 - val_loss: 3687251968.0000\n",
      "Epoch 247/1500\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 1262850816.0000 - val_loss: 3653378816.0000\n",
      "Epoch 248/1500\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 1268814720.0000 - val_loss: 3777776384.0000\n",
      "Epoch 249/1500\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 1260500480.0000 - val_loss: 3804330752.0000\n",
      "Epoch 250/1500\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 1266378624.0000 - val_loss: 3833379328.0000\n",
      "Epoch 251/1500\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 1270138752.0000 - val_loss: 3769640960.0000\n",
      "Epoch 252/1500\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 1258342656.0000 - val_loss: 3819688192.0000\n",
      "Epoch 253/1500\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 1258643072.0000 - val_loss: 3760730624.0000\n",
      "Epoch 254/1500\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 1240440320.0000 - val_loss: 3653766144.0000\n",
      "Epoch 255/1500\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 1268449408.0000 - val_loss: 3678788352.0000\n",
      "Epoch 256/1500\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 1251850624.0000 - val_loss: 3718509568.0000\n",
      "Epoch 257/1500\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 1264518784.0000 - val_loss: 3738788864.0000\n",
      "Epoch 258/1500\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 1248567424.0000 - val_loss: 3668675328.0000\n",
      "Epoch 259/1500\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 1248566016.0000 - val_loss: 3685301760.0000\n",
      "Epoch 260/1500\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 1248808704.0000 - val_loss: 3802367744.0000\n",
      "Epoch 261/1500\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 1244097280.0000 - val_loss: 3749381632.0000\n",
      "Epoch 262/1500\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 1230494336.0000 - val_loss: 3708868864.0000\n",
      "Epoch 263/1500\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 1243092480.0000 - val_loss: 3680625152.0000\n",
      "Epoch 264/1500\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 1236546944.0000 - val_loss: 3728132352.0000\n",
      "Epoch 265/1500\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 1240885120.0000 - val_loss: 3743524864.0000\n",
      "Epoch 266/1500\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 1240262656.0000 - val_loss: 3708489728.0000\n",
      "Epoch 267/1500\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 1243099008.0000 - val_loss: 3730052352.0000\n",
      "Epoch 268/1500\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 1234737152.0000 - val_loss: 3727246336.0000\n",
      "Epoch 269/1500\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 1238634496.0000 - val_loss: 3722947328.0000\n",
      "Epoch 270/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "117/117 [==============================] - 0s 2ms/step - loss: 1236163712.0000 - val_loss: 3726513920.0000\n",
      "Epoch 271/1500\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 1238205056.0000 - val_loss: 3701316864.0000\n",
      "Epoch 272/1500\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 1230014848.0000 - val_loss: 3735955968.0000\n",
      "Epoch 273/1500\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 1227297280.0000 - val_loss: 3666251264.0000\n",
      "Epoch 274/1500\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 1227519232.0000 - val_loss: 3780335104.0000\n",
      "Epoch 275/1500\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 1229527040.0000 - val_loss: 3795560192.0000\n",
      "Epoch 276/1500\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 1232715136.0000 - val_loss: 3736148992.0000\n",
      "Epoch 277/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 1228615552.0000 - val_loss: 3742871808.0000\n",
      "Epoch 278/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 1222783104.0000 - val_loss: 3722779904.0000\n",
      "Epoch 279/1500\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 1219586944.0000 - val_loss: 3744971776.0000\n",
      "Epoch 280/1500\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 1217001088.0000 - val_loss: 3740564992.0000\n",
      "Epoch 281/1500\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 1217113472.0000 - val_loss: 3748383488.0000\n",
      "Epoch 282/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 1223493760.0000 - val_loss: 3746260480.0000\n",
      "Epoch 283/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 1214083200.0000 - val_loss: 3763243520.0000\n",
      "Epoch 284/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 1213789184.0000 - val_loss: 3765603328.0000\n",
      "Epoch 285/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 1220173056.0000 - val_loss: 3795218432.0000\n",
      "Epoch 286/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 1213494400.0000 - val_loss: 3647761920.0000\n",
      "Epoch 287/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 1214762752.0000 - val_loss: 3685808128.0000\n",
      "Epoch 288/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 1211220992.0000 - val_loss: 3652167168.0000\n",
      "Epoch 289/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 1204085504.0000 - val_loss: 3736513536.0000\n",
      "Epoch 290/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 1209374592.0000 - val_loss: 3741182720.0000\n",
      "Epoch 291/1500\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 1201175424.0000 - val_loss: 3743002368.0000\n",
      "Epoch 292/1500\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 1216497664.0000 - val_loss: 3685040384.0000\n",
      "Epoch 293/1500\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 1206878720.0000 - val_loss: 3717534208.0000\n",
      "Epoch 294/1500\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 1205232768.0000 - val_loss: 3730084352.0000\n",
      "Epoch 295/1500\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 1199500416.0000 - val_loss: 3722397440.0000\n",
      "Epoch 296/1500\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 1197994752.0000 - val_loss: 3715659264.0000\n",
      "Epoch 297/1500\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 1196493440.0000 - val_loss: 3708159232.0000\n",
      "Epoch 298/1500\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 1194162304.0000 - val_loss: 3853227776.0000\n",
      "Epoch 299/1500\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 1194249856.0000 - val_loss: 3703033600.0000\n",
      "Epoch 300/1500\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 1203832576.0000 - val_loss: 3711819776.0000\n",
      "Epoch 301/1500\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 1194167168.0000 - val_loss: 3656133120.0000\n",
      "Epoch 302/1500\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 1194612096.0000 - val_loss: 3673443840.0000\n",
      "Epoch 303/1500\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 1192076672.0000 - val_loss: 3677766400.0000\n",
      "Epoch 304/1500\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 1188153728.0000 - val_loss: 3703857152.0000\n",
      "Epoch 305/1500\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 1185546112.0000 - val_loss: 3705773824.0000\n",
      "Epoch 306/1500\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 1192920960.0000 - val_loss: 3746646016.0000\n",
      "Epoch 307/1500\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 1190476800.0000 - val_loss: 3740046592.0000\n",
      "Epoch 308/1500\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 1184485248.0000 - val_loss: 3776424448.0000\n",
      "Epoch 309/1500\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 1182483712.0000 - val_loss: 3755143680.0000\n",
      "Epoch 310/1500\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 1175984512.0000 - val_loss: 3691365376.0000\n",
      "Epoch 311/1500\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 1179700736.0000 - val_loss: 3622782976.0000\n",
      "Epoch 312/1500\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 1174277504.0000 - val_loss: 3644894464.0000\n",
      "Epoch 313/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 1193342208.0000 - val_loss: 3640264704.0000\n",
      "Epoch 314/1500\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 1187646592.0000 - val_loss: 3713310720.0000\n",
      "Epoch 315/1500\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 1182564096.0000 - val_loss: 3635957504.0000\n",
      "Epoch 316/1500\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 1174437760.0000 - val_loss: 3754567680.0000\n",
      "Epoch 317/1500\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 1172363264.0000 - val_loss: 3756577536.0000\n",
      "Epoch 318/1500\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 1173113216.0000 - val_loss: 3626485760.0000\n",
      "Epoch 319/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 1180366080.0000 - val_loss: 3679720192.0000\n",
      "Epoch 320/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 1185254784.0000 - val_loss: 3776764160.0000\n",
      "Epoch 321/1500\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 1167521152.0000 - val_loss: 3717121024.0000\n",
      "Epoch 322/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 1169058560.0000 - val_loss: 3686094336.0000\n",
      "Epoch 323/1500\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 1164582528.0000 - val_loss: 3729365248.0000\n",
      "Epoch 324/1500\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 1164396032.0000 - val_loss: 3668760832.0000\n",
      "Epoch 325/1500\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 1165274880.0000 - val_loss: 3722698752.0000\n",
      "Epoch 326/1500\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 1163163776.0000 - val_loss: 3744748800.0000\n",
      "Epoch 327/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 1164979968.0000 - val_loss: 3728660992.0000\n",
      "Epoch 328/1500\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 1165909376.0000 - val_loss: 3692240384.0000\n",
      "Epoch 329/1500\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 1153612288.0000 - val_loss: 3738690560.0000\n",
      "Epoch 330/1500\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 1164577664.0000 - val_loss: 3748632832.0000\n",
      "Epoch 331/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 1164180992.0000 - val_loss: 3748900096.0000\n",
      "Epoch 332/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 1154511488.0000 - val_loss: 3728444672.0000\n",
      "Epoch 333/1500\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 1154079744.0000 - val_loss: 3708435200.0000\n",
      "Epoch 334/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 1154692608.0000 - val_loss: 3674253824.0000\n",
      "Epoch 335/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 1148665856.0000 - val_loss: 3783466496.0000\n",
      "Epoch 336/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 1152125824.0000 - val_loss: 3689880320.0000\n",
      "Epoch 337/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "117/117 [==============================] - 0s 1ms/step - loss: 1142360064.0000 - val_loss: 3725563648.0000\n",
      "Epoch 338/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 1152394496.0000 - val_loss: 3648240896.0000\n",
      "Epoch 339/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 1148173312.0000 - val_loss: 3645588224.0000\n",
      "Epoch 340/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 1147976320.0000 - val_loss: 3693575936.0000\n",
      "Epoch 341/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 1139701760.0000 - val_loss: 3717764096.0000\n",
      "Epoch 342/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 1143314048.0000 - val_loss: 3714534144.0000\n",
      "Epoch 343/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 1145997184.0000 - val_loss: 3656715008.0000\n",
      "Epoch 344/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 1141048320.0000 - val_loss: 3657009408.0000\n",
      "Epoch 345/1500\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 1141282560.0000 - val_loss: 3627130624.0000\n",
      "Epoch 346/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 1141703680.0000 - val_loss: 3565956608.0000\n",
      "Epoch 347/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 1134997376.0000 - val_loss: 3600786688.0000\n",
      "Epoch 348/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 1127203840.0000 - val_loss: 3571310848.0000\n",
      "Epoch 349/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 1143340800.0000 - val_loss: 3598390272.0000\n",
      "Epoch 350/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 1128407552.0000 - val_loss: 3641822720.0000\n",
      "Epoch 351/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 1130072320.0000 - val_loss: 3687678208.0000\n",
      "Epoch 352/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 1137059840.0000 - val_loss: 3665442816.0000\n",
      "Epoch 353/1500\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 1128889856.0000 - val_loss: 3633259776.0000\n",
      "Epoch 354/1500\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 1126614912.0000 - val_loss: 3638329856.0000\n",
      "Epoch 355/1500\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 1126526848.0000 - val_loss: 3564314368.0000\n",
      "Epoch 356/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 1126890496.0000 - val_loss: 3577255936.0000\n",
      "Epoch 357/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 1142872704.0000 - val_loss: 3637815552.0000\n",
      "Epoch 358/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 1129622912.0000 - val_loss: 3612007936.0000\n",
      "Epoch 359/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 1118597760.0000 - val_loss: 3663830784.0000\n",
      "Epoch 360/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 1124071424.0000 - val_loss: 3636039168.0000\n",
      "Epoch 361/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 1121496576.0000 - val_loss: 3602823424.0000\n",
      "Epoch 362/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 1121242624.0000 - val_loss: 3581592576.0000\n",
      "Epoch 363/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 1113557376.0000 - val_loss: 3669924096.0000\n",
      "Epoch 364/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 1114999040.0000 - val_loss: 3639720960.0000\n",
      "Epoch 365/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 1109749504.0000 - val_loss: 3640570368.0000\n",
      "Epoch 366/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 1130185600.0000 - val_loss: 3576306944.0000\n",
      "Epoch 367/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 1113140992.0000 - val_loss: 3583853568.0000\n",
      "Epoch 368/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 1111197824.0000 - val_loss: 3562947840.0000\n",
      "Epoch 369/1500\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 1114648704.0000 - val_loss: 3690891008.0000\n",
      "Epoch 370/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 1121724544.0000 - val_loss: 3694139904.0000\n",
      "Epoch 371/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 1115119616.0000 - val_loss: 3617561856.0000\n",
      "Epoch 372/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 1106025984.0000 - val_loss: 3603796992.0000\n",
      "Epoch 373/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 1110314496.0000 - val_loss: 3553260800.0000\n",
      "Epoch 374/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 1099837056.0000 - val_loss: 3581060096.0000\n",
      "Epoch 375/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 1098319616.0000 - val_loss: 3614125568.0000\n",
      "Epoch 376/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 1104018944.0000 - val_loss: 3586691328.0000\n",
      "Epoch 377/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 1100887808.0000 - val_loss: 3589066240.0000\n",
      "Epoch 378/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 1105367808.0000 - val_loss: 3582163456.0000\n",
      "Epoch 379/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 1107905792.0000 - val_loss: 3537356800.0000\n",
      "Epoch 380/1500\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 1100939264.0000 - val_loss: 3548649984.0000\n",
      "Epoch 381/1500\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 1100092800.0000 - val_loss: 3680554752.0000\n",
      "Epoch 382/1500\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 1106704128.0000 - val_loss: 3603556096.0000\n",
      "Epoch 383/1500\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 1100416000.0000 - val_loss: 3543188224.0000\n",
      "Epoch 384/1500\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 1090662528.0000 - val_loss: 3603248896.0000\n",
      "Epoch 385/1500\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 1092112768.0000 - val_loss: 3694841344.0000\n",
      "Epoch 386/1500\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 1091729664.0000 - val_loss: 3637349632.0000\n",
      "Epoch 387/1500\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 1091116928.0000 - val_loss: 3591897344.0000\n",
      "Epoch 388/1500\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 1091193088.0000 - val_loss: 3539048448.0000\n",
      "Epoch 389/1500\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 1096374400.0000 - val_loss: 3605016064.0000\n",
      "Epoch 390/1500\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 1084579328.0000 - val_loss: 3644057344.0000\n",
      "Epoch 391/1500\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 1090248704.0000 - val_loss: 3640068608.0000\n",
      "Epoch 392/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 1091667968.0000 - val_loss: 3679371776.0000\n",
      "Epoch 393/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 1091552896.0000 - val_loss: 3587236608.0000\n",
      "Epoch 394/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 1085682688.0000 - val_loss: 3585611776.0000\n",
      "Epoch 395/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 1086285312.0000 - val_loss: 3579274240.0000\n",
      "Epoch 396/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 1077707264.0000 - val_loss: 3540678912.0000\n",
      "Epoch 397/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 1082009856.0000 - val_loss: 3591297792.0000\n",
      "Epoch 398/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 1086269312.0000 - val_loss: 3700694784.0000\n",
      "Epoch 399/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 1090679680.0000 - val_loss: 3513478144.0000\n",
      "Epoch 400/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 1082686336.0000 - val_loss: 3536607488.0000\n",
      "Epoch 401/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 1076201344.0000 - val_loss: 3585101824.0000\n",
      "Epoch 402/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 1073954304.0000 - val_loss: 3614884864.0000\n",
      "Epoch 403/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 1075556608.0000 - val_loss: 3531488256.0000\n",
      "Epoch 404/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "117/117 [==============================] - 0s 1ms/step - loss: 1065599104.0000 - val_loss: 3546490112.0000\n",
      "Epoch 405/1500\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 1083550080.0000 - val_loss: 3595065600.0000\n",
      "Epoch 406/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 1057410752.0000 - val_loss: 3525689088.0000\n",
      "Epoch 407/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 1081504000.0000 - val_loss: 3609123072.0000\n",
      "Epoch 408/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 1067791040.0000 - val_loss: 3548678400.0000\n",
      "Epoch 409/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 1063537216.0000 - val_loss: 3644695296.0000\n",
      "Epoch 410/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 1065598976.0000 - val_loss: 3566234368.0000\n",
      "Epoch 411/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 1071961600.0000 - val_loss: 3505042688.0000\n",
      "Epoch 412/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 1071769344.0000 - val_loss: 3492215040.0000\n",
      "Epoch 413/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 1059661184.0000 - val_loss: 3618145280.0000\n",
      "Epoch 414/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 1067202176.0000 - val_loss: 3554740224.0000\n",
      "Epoch 415/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 1063153408.0000 - val_loss: 3556644864.0000\n",
      "Epoch 416/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 1071467648.0000 - val_loss: 3606750976.0000\n",
      "Epoch 417/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 1064790528.0000 - val_loss: 3761561088.0000\n",
      "Epoch 418/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 1068692352.0000 - val_loss: 3611416064.0000\n",
      "Epoch 419/1500\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 1061239424.0000 - val_loss: 3499409920.0000\n",
      "Epoch 420/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 1056878336.0000 - val_loss: 3537823232.0000\n",
      "Epoch 421/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 1054880960.0000 - val_loss: 3534755072.0000\n",
      "Epoch 422/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 1053746880.0000 - val_loss: 3625059840.0000\n",
      "Epoch 423/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 1058204480.0000 - val_loss: 3582995200.0000\n",
      "Epoch 424/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 1058883264.0000 - val_loss: 3572556544.0000\n",
      "Epoch 425/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 1055070272.0000 - val_loss: 3467380480.0000\n",
      "Epoch 426/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 1052738176.0000 - val_loss: 3761170176.0000\n",
      "Epoch 427/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 1059391616.0000 - val_loss: 3561132800.0000\n",
      "Epoch 428/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 1045801152.0000 - val_loss: 3672152320.0000\n",
      "Epoch 429/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 1050443776.0000 - val_loss: 3548403968.0000\n",
      "Epoch 430/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 1053512256.0000 - val_loss: 3553572096.0000\n",
      "Epoch 431/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 1052513664.0000 - val_loss: 3481483776.0000\n",
      "Epoch 432/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 1047946688.0000 - val_loss: 3519261184.0000\n",
      "Epoch 433/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 1048193472.0000 - val_loss: 3551090688.0000\n",
      "Epoch 434/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 1048613312.0000 - val_loss: 3451028480.0000\n",
      "Epoch 435/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 1043944320.0000 - val_loss: 3675574016.0000\n",
      "Epoch 436/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 1047697152.0000 - val_loss: 3522020608.0000\n",
      "Epoch 437/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 1061010432.0000 - val_loss: 3456840192.0000\n",
      "Epoch 438/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 1040703808.0000 - val_loss: 3548650496.0000\n",
      "Epoch 439/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 1038257280.0000 - val_loss: 3535988480.0000\n",
      "Epoch 440/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 1040884736.0000 - val_loss: 3522826752.0000\n",
      "Epoch 441/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 1042466496.0000 - val_loss: 3525051136.0000\n",
      "Epoch 442/1500\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 1047497792.0000 - val_loss: 3531829248.0000\n",
      "Epoch 443/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 1039185408.0000 - val_loss: 3485221888.0000\n",
      "Epoch 444/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 1035204864.0000 - val_loss: 3522065664.0000\n",
      "Epoch 445/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 1034176064.0000 - val_loss: 3549498624.0000\n",
      "Epoch 446/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 1037647168.0000 - val_loss: 3522232064.0000\n",
      "Epoch 447/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 1032906688.0000 - val_loss: 3498464512.0000\n",
      "Epoch 448/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 1029399488.0000 - val_loss: 3545985792.0000\n",
      "Epoch 449/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 1038951040.0000 - val_loss: 3607557376.0000\n",
      "Epoch 450/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 1032228736.0000 - val_loss: 3596496640.0000\n",
      "Epoch 451/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 1023033664.0000 - val_loss: 3418117888.0000\n",
      "Epoch 452/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 1030015680.0000 - val_loss: 3494857472.0000\n",
      "Epoch 453/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 1025816448.0000 - val_loss: 3403147776.0000\n",
      "Epoch 454/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 1025179584.0000 - val_loss: 3509989888.0000\n",
      "Epoch 455/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 1023090176.0000 - val_loss: 3520197632.0000\n",
      "Epoch 456/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 1023485632.0000 - val_loss: 3516987136.0000\n",
      "Epoch 457/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 1030341952.0000 - val_loss: 3594310912.0000\n",
      "Epoch 458/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 1028477376.0000 - val_loss: 3556618240.0000\n",
      "Epoch 459/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 1020530176.0000 - val_loss: 3457083904.0000\n",
      "Epoch 460/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 1017789696.0000 - val_loss: 3487308800.0000\n",
      "Epoch 461/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 1024867328.0000 - val_loss: 3547401472.0000\n",
      "Epoch 462/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 1019141888.0000 - val_loss: 3517339136.0000\n",
      "Epoch 463/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 1018052928.0000 - val_loss: 3523129344.0000\n",
      "Epoch 464/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 1012399680.0000 - val_loss: 3505858304.0000\n",
      "Epoch 465/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 1005828352.0000 - val_loss: 3513699840.0000\n",
      "Epoch 466/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 1017849536.0000 - val_loss: 3477442816.0000\n",
      "Epoch 467/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 1018531648.0000 - val_loss: 3463168000.0000\n",
      "Epoch 468/1500\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 1016547008.0000 - val_loss: 3546301952.0000\n",
      "Epoch 469/1500\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 1016271296.0000 - val_loss: 3404420352.0000\n",
      "Epoch 470/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 1016006592.0000 - val_loss: 3441726464.0000\n",
      "Epoch 471/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "117/117 [==============================] - 0s 1ms/step - loss: 1012972608.0000 - val_loss: 3365687808.0000\n",
      "Epoch 472/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 1021823808.0000 - val_loss: 3450664704.0000\n",
      "Epoch 473/1500\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 1007468800.0000 - val_loss: 3443913984.0000\n",
      "Epoch 474/1500\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 1016523584.0000 - val_loss: 3419694080.0000\n",
      "Epoch 475/1500\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 1009181824.0000 - val_loss: 3477546496.0000\n",
      "Epoch 476/1500\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 1003977472.0000 - val_loss: 3465403136.0000\n",
      "Epoch 477/1500\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 1017788096.0000 - val_loss: 3446526208.0000\n",
      "Epoch 478/1500\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 1006451264.0000 - val_loss: 3494889216.0000\n",
      "Epoch 479/1500\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 1002747648.0000 - val_loss: 3371424000.0000\n",
      "Epoch 480/1500\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 1002110272.0000 - val_loss: 3366690816.0000\n",
      "Epoch 481/1500\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 1006414144.0000 - val_loss: 3504456704.0000\n",
      "Epoch 482/1500\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 1005407168.0000 - val_loss: 3386892288.0000\n",
      "Epoch 483/1500\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 1014709120.0000 - val_loss: 3402496768.0000\n",
      "Epoch 484/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 1003398080.0000 - val_loss: 3494077696.0000\n",
      "Epoch 485/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 991139712.0000 - val_loss: 3419960064.0000\n",
      "Epoch 486/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 998414976.0000 - val_loss: 3420314112.0000\n",
      "Epoch 487/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 996475264.0000 - val_loss: 3363790848.0000\n",
      "Epoch 488/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 992573760.0000 - val_loss: 3438052096.0000\n",
      "Epoch 489/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 994331200.0000 - val_loss: 3397446912.0000\n",
      "Epoch 490/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 999163456.0000 - val_loss: 3347161088.0000\n",
      "Epoch 491/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 983170624.0000 - val_loss: 3468007680.0000\n",
      "Epoch 492/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 997769024.0000 - val_loss: 3447478528.0000\n",
      "Epoch 493/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 987602688.0000 - val_loss: 3441134080.0000\n",
      "Epoch 494/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 989673600.0000 - val_loss: 3428383744.0000\n",
      "Epoch 495/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 996198400.0000 - val_loss: 3417968896.0000\n",
      "Epoch 496/1500\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 997409408.0000 - val_loss: 3468000768.0000\n",
      "Epoch 497/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 988154944.0000 - val_loss: 3437334784.0000\n",
      "Epoch 498/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 984364224.0000 - val_loss: 3478066432.0000\n",
      "Epoch 499/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 988488448.0000 - val_loss: 3405463296.0000\n",
      "Epoch 500/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 982651264.0000 - val_loss: 3405039104.0000\n",
      "Epoch 501/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 982125056.0000 - val_loss: 3379169024.0000\n",
      "Epoch 502/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 984376448.0000 - val_loss: 3544951296.0000\n",
      "Epoch 503/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 986267136.0000 - val_loss: 3417500160.0000\n",
      "Epoch 504/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 979941248.0000 - val_loss: 3428452864.0000\n",
      "Epoch 505/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 982772480.0000 - val_loss: 3463818240.0000\n",
      "Epoch 506/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 988275136.0000 - val_loss: 3417699072.0000\n",
      "Epoch 507/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 977153344.0000 - val_loss: 3467746560.0000\n",
      "Epoch 508/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 979297344.0000 - val_loss: 3334314240.0000\n",
      "Epoch 509/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 983965504.0000 - val_loss: 3372260864.0000\n",
      "Epoch 510/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 976620864.0000 - val_loss: 3377318656.0000\n",
      "Epoch 511/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 969409536.0000 - val_loss: 3401637376.0000\n",
      "Epoch 512/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 978957312.0000 - val_loss: 3447890176.0000\n",
      "Epoch 513/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 974507840.0000 - val_loss: 3428011776.0000\n",
      "Epoch 514/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 974281792.0000 - val_loss: 3371265792.0000\n",
      "Epoch 515/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 977417280.0000 - val_loss: 3384157696.0000\n",
      "Epoch 516/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 969143552.0000 - val_loss: 3307291648.0000\n",
      "Epoch 517/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 968133952.0000 - val_loss: 3338042368.0000\n",
      "Epoch 518/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 963050560.0000 - val_loss: 3371315712.0000\n",
      "Epoch 519/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 972318272.0000 - val_loss: 3360616192.0000\n",
      "Epoch 520/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 966288384.0000 - val_loss: 3362378752.0000\n",
      "Epoch 521/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 963888128.0000 - val_loss: 3261525504.0000\n",
      "Epoch 522/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 979968256.0000 - val_loss: 3318171648.0000\n",
      "Epoch 523/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 962566592.0000 - val_loss: 3275085568.0000\n",
      "Epoch 524/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 973910016.0000 - val_loss: 3309894912.0000\n",
      "Epoch 525/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 959724032.0000 - val_loss: 3315530752.0000\n",
      "Epoch 526/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 965553536.0000 - val_loss: 3374603264.0000\n",
      "Epoch 527/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 961361664.0000 - val_loss: 3367257088.0000\n",
      "Epoch 528/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 955225216.0000 - val_loss: 3390871040.0000\n",
      "Epoch 529/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 956759680.0000 - val_loss: 3388112896.0000\n",
      "Epoch 530/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 960048064.0000 - val_loss: 3306105600.0000\n",
      "Epoch 531/1500\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 955022400.0000 - val_loss: 3351444736.0000\n",
      "Epoch 532/1500\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 967247360.0000 - val_loss: 3340110080.0000\n",
      "Epoch 533/1500\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 951034496.0000 - val_loss: 3308039680.0000\n",
      "Epoch 534/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 962462720.0000 - val_loss: 3302924800.0000\n",
      "Epoch 535/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 958453696.0000 - val_loss: 3366850816.0000\n",
      "Epoch 536/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 958623552.0000 - val_loss: 3261041664.0000\n",
      "Epoch 537/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 945890944.0000 - val_loss: 3371130880.0000\n",
      "Epoch 538/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "117/117 [==============================] - 0s 1ms/step - loss: 954701376.0000 - val_loss: 3451184640.0000\n",
      "Epoch 539/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 955200192.0000 - val_loss: 3311879424.0000\n",
      "Epoch 540/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 947771776.0000 - val_loss: 3374071040.0000\n",
      "Epoch 541/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 953727040.0000 - val_loss: 3295247616.0000\n",
      "Epoch 542/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 957558656.0000 - val_loss: 3353860352.0000\n",
      "Epoch 543/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 943045376.0000 - val_loss: 3229035776.0000\n",
      "Epoch 544/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 949029440.0000 - val_loss: 3348980224.0000\n",
      "Epoch 545/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 943815104.0000 - val_loss: 3292037376.0000\n",
      "Epoch 546/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 949522432.0000 - val_loss: 3208850944.0000\n",
      "Epoch 547/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 949434112.0000 - val_loss: 3313535488.0000\n",
      "Epoch 548/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 953490368.0000 - val_loss: 3313533952.0000\n",
      "Epoch 549/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 939428544.0000 - val_loss: 3212016128.0000\n",
      "Epoch 550/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 949592576.0000 - val_loss: 3266884608.0000\n",
      "Epoch 551/1500\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 946167680.0000 - val_loss: 3205306624.0000\n",
      "Epoch 552/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 942749440.0000 - val_loss: 3244686080.0000\n",
      "Epoch 553/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 929263744.0000 - val_loss: 3334818560.0000\n",
      "Epoch 554/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 938132032.0000 - val_loss: 3329640960.0000\n",
      "Epoch 555/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 940807232.0000 - val_loss: 3222217984.0000\n",
      "Epoch 556/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 931818560.0000 - val_loss: 3267783936.0000\n",
      "Epoch 557/1500\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 948924800.0000 - val_loss: 3287190272.0000\n",
      "Epoch 558/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 928998784.0000 - val_loss: 3339038976.0000\n",
      "Epoch 559/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 936373952.0000 - val_loss: 3258066176.0000\n",
      "Epoch 560/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 933442368.0000 - val_loss: 3395893248.0000\n",
      "Epoch 561/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 926556416.0000 - val_loss: 3318163456.0000\n",
      "Epoch 562/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 920570880.0000 - val_loss: 3193060608.0000\n",
      "Epoch 563/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 930955904.0000 - val_loss: 3293716480.0000\n",
      "Epoch 564/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 923765824.0000 - val_loss: 3234441728.0000\n",
      "Epoch 565/1500\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 923237888.0000 - val_loss: 3405593344.0000\n",
      "Epoch 566/1500\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 938829056.0000 - val_loss: 3293503488.0000\n",
      "Epoch 567/1500\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 926853120.0000 - val_loss: 3321047040.0000\n",
      "Epoch 568/1500\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 925048576.0000 - val_loss: 3216378624.0000\n",
      "Epoch 569/1500\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 924165120.0000 - val_loss: 3192827392.0000\n",
      "Epoch 570/1500\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 919277248.0000 - val_loss: 3193465600.0000\n",
      "Epoch 571/1500\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 916912960.0000 - val_loss: 3291100160.0000\n",
      "Epoch 572/1500\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 922450496.0000 - val_loss: 3197135104.0000\n",
      "Epoch 573/1500\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 935262592.0000 - val_loss: 3211227648.0000\n",
      "Epoch 574/1500\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 922685312.0000 - val_loss: 3250542848.0000\n",
      "Epoch 575/1500\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 914852288.0000 - val_loss: 3210464512.0000\n",
      "Epoch 576/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 919518784.0000 - val_loss: 3211292928.0000\n",
      "Epoch 577/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 929417600.0000 - val_loss: 3253242112.0000\n",
      "Epoch 578/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 912976064.0000 - val_loss: 3265594368.0000\n",
      "Epoch 579/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 914997504.0000 - val_loss: 3284054784.0000\n",
      "Epoch 580/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 914347968.0000 - val_loss: 3188578048.0000\n",
      "Epoch 581/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 906761920.0000 - val_loss: 3180999424.0000\n",
      "Epoch 582/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 913683136.0000 - val_loss: 3189554176.0000\n",
      "Epoch 583/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 911038784.0000 - val_loss: 3214200064.0000\n",
      "Epoch 584/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 908341696.0000 - val_loss: 3322555904.0000\n",
      "Epoch 585/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 903469568.0000 - val_loss: 3237748480.0000\n",
      "Epoch 586/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 906089856.0000 - val_loss: 3113812480.0000\n",
      "Epoch 587/1500\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 905119552.0000 - val_loss: 3176910080.0000\n",
      "Epoch 588/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 904790272.0000 - val_loss: 3367751168.0000\n",
      "Epoch 589/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 915204544.0000 - val_loss: 3206066432.0000\n",
      "Epoch 590/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 896871744.0000 - val_loss: 3106529024.0000\n",
      "Epoch 591/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 904714816.0000 - val_loss: 3224360960.0000\n",
      "Epoch 592/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 911350400.0000 - val_loss: 3154350848.0000\n",
      "Epoch 593/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 903410304.0000 - val_loss: 3244335104.0000\n",
      "Epoch 594/1500\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 912116160.0000 - val_loss: 3157030656.0000\n",
      "Epoch 595/1500\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 904410880.0000 - val_loss: 3146663680.0000\n",
      "Epoch 596/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 900082624.0000 - val_loss: 3234748928.0000\n",
      "Epoch 597/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 908676224.0000 - val_loss: 3209772800.0000\n",
      "Epoch 598/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 902684736.0000 - val_loss: 3179168512.0000\n",
      "Epoch 599/1500\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 887177152.0000 - val_loss: 3248776192.0000\n",
      "Epoch 600/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 898505536.0000 - val_loss: 3159702784.0000\n",
      "Epoch 601/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 899064640.0000 - val_loss: 3339802880.0000\n",
      "Epoch 602/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 899988544.0000 - val_loss: 3155884544.0000\n",
      "Epoch 603/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 894608128.0000 - val_loss: 3074496256.0000\n",
      "Epoch 604/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 891734080.0000 - val_loss: 3187098880.0000\n",
      "Epoch 605/1500\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 896054720.0000 - val_loss: 3143993856.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 606/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 895891392.0000 - val_loss: 3116296448.0000\n",
      "Epoch 607/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 898265024.0000 - val_loss: 3189343232.0000\n",
      "Epoch 608/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 891055488.0000 - val_loss: 3233686528.0000\n",
      "Epoch 609/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 891643648.0000 - val_loss: 3138295296.0000\n",
      "Epoch 610/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 883415488.0000 - val_loss: 3135330304.0000\n",
      "Epoch 611/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 882875072.0000 - val_loss: 3001572864.0000\n",
      "Epoch 612/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 886889792.0000 - val_loss: 3157195264.0000\n",
      "Epoch 613/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 889617152.0000 - val_loss: 3063074816.0000\n",
      "Epoch 614/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 886521280.0000 - val_loss: 3105519360.0000\n",
      "Epoch 615/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 895790272.0000 - val_loss: 3134813696.0000\n",
      "Epoch 616/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 884609920.0000 - val_loss: 3180962048.0000\n",
      "Epoch 617/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 885190400.0000 - val_loss: 3051165952.0000\n",
      "Epoch 618/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 885156480.0000 - val_loss: 3141301504.0000\n",
      "Epoch 619/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 881460672.0000 - val_loss: 3108264960.0000\n",
      "Epoch 620/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 875323200.0000 - val_loss: 3097081344.0000\n",
      "Epoch 621/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 876970304.0000 - val_loss: 3103879936.0000\n",
      "Epoch 622/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 880226944.0000 - val_loss: 3128188672.0000\n",
      "Epoch 623/1500\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 877968384.0000 - val_loss: 3103148544.0000\n",
      "Epoch 624/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 882914240.0000 - val_loss: 3112361728.0000\n",
      "Epoch 625/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 874560256.0000 - val_loss: 3057551104.0000\n",
      "Epoch 626/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 875554880.0000 - val_loss: 3160732416.0000\n",
      "Epoch 627/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 885219136.0000 - val_loss: 3136144384.0000\n",
      "Epoch 628/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 864364608.0000 - val_loss: 3050286336.0000\n",
      "Epoch 629/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 886237760.0000 - val_loss: 3039458816.0000\n",
      "Epoch 630/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 877239552.0000 - val_loss: 3051176704.0000\n",
      "Epoch 631/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 881635776.0000 - val_loss: 3170386944.0000\n",
      "Epoch 632/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 877628544.0000 - val_loss: 3092957952.0000\n",
      "Epoch 633/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 879832768.0000 - val_loss: 3117721856.0000\n",
      "Epoch 634/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 870949760.0000 - val_loss: 3072241152.0000\n",
      "Epoch 635/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 871299648.0000 - val_loss: 3094511360.0000\n",
      "Epoch 636/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 870995392.0000 - val_loss: 3064422912.0000\n",
      "Epoch 637/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 865686336.0000 - val_loss: 3135318528.0000\n",
      "Epoch 638/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 862821056.0000 - val_loss: 3051719424.0000\n",
      "Epoch 639/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 875588288.0000 - val_loss: 3050436864.0000\n",
      "Epoch 640/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 861126144.0000 - val_loss: 3034404352.0000\n",
      "Epoch 641/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 870878720.0000 - val_loss: 3112669440.0000\n",
      "Epoch 642/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 861651328.0000 - val_loss: 3084379904.0000\n",
      "Epoch 643/1500\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 858055552.0000 - val_loss: 3080151040.0000\n",
      "Epoch 644/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 849552192.0000 - val_loss: 3106108160.0000\n",
      "Epoch 645/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 863109952.0000 - val_loss: 2963289344.0000\n",
      "Epoch 646/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 861299392.0000 - val_loss: 3050492416.0000\n",
      "Epoch 647/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 868839872.0000 - val_loss: 3025010688.0000\n",
      "Epoch 648/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 862315456.0000 - val_loss: 3022562816.0000\n",
      "Epoch 649/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 863032192.0000 - val_loss: 3053182976.0000\n",
      "Epoch 650/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 857312896.0000 - val_loss: 3091624448.0000\n",
      "Epoch 651/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 855835968.0000 - val_loss: 2944418304.0000\n",
      "Epoch 652/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 853452160.0000 - val_loss: 3079732736.0000\n",
      "Epoch 653/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 853831168.0000 - val_loss: 3016731136.0000\n",
      "Epoch 654/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 852621632.0000 - val_loss: 3072634368.0000\n",
      "Epoch 655/1500\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 850806272.0000 - val_loss: 2973461504.0000\n",
      "Epoch 656/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 853510528.0000 - val_loss: 2983112448.0000\n",
      "Epoch 657/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 849618880.0000 - val_loss: 3014967808.0000\n",
      "Epoch 658/1500\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 852615168.0000 - val_loss: 2983992576.0000\n",
      "Epoch 659/1500\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 859147776.0000 - val_loss: 3082614016.0000\n",
      "Epoch 660/1500\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 864551296.0000 - val_loss: 3025407232.0000\n",
      "Epoch 661/1500\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 855636672.0000 - val_loss: 3018554624.0000\n",
      "Epoch 662/1500\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 856138688.0000 - val_loss: 3097627648.0000\n",
      "Epoch 663/1500\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 843042752.0000 - val_loss: 3080505088.0000\n",
      "Epoch 664/1500\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 850442496.0000 - val_loss: 3139934976.0000\n",
      "Epoch 665/1500\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 849150592.0000 - val_loss: 2918007040.0000\n",
      "Epoch 666/1500\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 861073728.0000 - val_loss: 2979564288.0000\n",
      "Epoch 667/1500\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 850371712.0000 - val_loss: 3050667776.0000\n",
      "Epoch 668/1500\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 854690816.0000 - val_loss: 2935599616.0000\n",
      "Epoch 669/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 844907712.0000 - val_loss: 3022858752.0000\n",
      "Epoch 670/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 841268416.0000 - val_loss: 2997238784.0000\n",
      "Epoch 671/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 855257728.0000 - val_loss: 2966671104.0000\n",
      "Epoch 672/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 842967936.0000 - val_loss: 2939424256.0000\n",
      "Epoch 673/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "117/117 [==============================] - 0s 1ms/step - loss: 852473024.0000 - val_loss: 2954605056.0000\n",
      "Epoch 674/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 855416896.0000 - val_loss: 3083480064.0000\n",
      "Epoch 675/1500\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 842260096.0000 - val_loss: 2985097728.0000\n",
      "Epoch 676/1500\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 831599936.0000 - val_loss: 2846277632.0000\n",
      "Epoch 677/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 840170688.0000 - val_loss: 2937329408.0000\n",
      "Epoch 678/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 828375552.0000 - val_loss: 3031741696.0000\n",
      "Epoch 679/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 850849216.0000 - val_loss: 3102880000.0000\n",
      "Epoch 680/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 836229504.0000 - val_loss: 3000151552.0000\n",
      "Epoch 681/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 836964480.0000 - val_loss: 3092006656.0000\n",
      "Epoch 682/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 847816448.0000 - val_loss: 2995083008.0000\n",
      "Epoch 683/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 829867456.0000 - val_loss: 2974225664.0000\n",
      "Epoch 684/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 836336768.0000 - val_loss: 2963153920.0000\n",
      "Epoch 685/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 823090048.0000 - val_loss: 2974290432.0000\n",
      "Epoch 686/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 831172608.0000 - val_loss: 2865546240.0000\n",
      "Epoch 687/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 821711168.0000 - val_loss: 2889594112.0000\n",
      "Epoch 688/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 833690816.0000 - val_loss: 2998292480.0000\n",
      "Epoch 689/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 826319360.0000 - val_loss: 2967102720.0000\n",
      "Epoch 690/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 815153024.0000 - val_loss: 2942459904.0000\n",
      "Epoch 691/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 827681664.0000 - val_loss: 2936779776.0000\n",
      "Epoch 692/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 827205952.0000 - val_loss: 3043734016.0000\n",
      "Epoch 693/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 819376320.0000 - val_loss: 2964671744.0000\n",
      "Epoch 694/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 823753600.0000 - val_loss: 2910221824.0000\n",
      "Epoch 695/1500\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 832823936.0000 - val_loss: 2947173376.0000\n",
      "Epoch 696/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 834424832.0000 - val_loss: 2897186560.0000\n",
      "Epoch 697/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 814799296.0000 - val_loss: 2871208192.0000\n",
      "Epoch 698/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 821141440.0000 - val_loss: 2838484736.0000\n",
      "Epoch 699/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 823850624.0000 - val_loss: 2884844032.0000\n",
      "Epoch 700/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 829492992.0000 - val_loss: 2888204544.0000\n",
      "Epoch 701/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 813597312.0000 - val_loss: 2849233152.0000\n",
      "Epoch 702/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 811285760.0000 - val_loss: 2944148480.0000\n",
      "Epoch 703/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 832008064.0000 - val_loss: 2916861184.0000\n",
      "Epoch 704/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 827015040.0000 - val_loss: 2933454336.0000\n",
      "Epoch 705/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 819705792.0000 - val_loss: 2882233856.0000\n",
      "Epoch 706/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 805140224.0000 - val_loss: 2931821568.0000\n",
      "Epoch 707/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 806068928.0000 - val_loss: 2896041216.0000\n",
      "Epoch 708/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 814735040.0000 - val_loss: 2886007808.0000\n",
      "Epoch 709/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 811773568.0000 - val_loss: 2949533952.0000\n",
      "Epoch 710/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 806236480.0000 - val_loss: 2844942080.0000\n",
      "Epoch 711/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 821620416.0000 - val_loss: 2825210880.0000\n",
      "Epoch 712/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 805947392.0000 - val_loss: 2902322944.0000\n",
      "Epoch 713/1500\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 820590400.0000 - val_loss: 2872558592.0000\n",
      "Epoch 714/1500\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 802843200.0000 - val_loss: 2875542784.0000\n",
      "Epoch 715/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 811974016.0000 - val_loss: 2841947648.0000\n",
      "Epoch 716/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 819587968.0000 - val_loss: 2958165760.0000\n",
      "Epoch 717/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 817711616.0000 - val_loss: 2881279488.0000\n",
      "Epoch 718/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 800006656.0000 - val_loss: 2788759552.0000\n",
      "Epoch 719/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 816039424.0000 - val_loss: 2906913024.0000\n",
      "Epoch 720/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 811851968.0000 - val_loss: 2864938240.0000\n",
      "Epoch 721/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 806965696.0000 - val_loss: 2808331520.0000\n",
      "Epoch 722/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 794429312.0000 - val_loss: 2902150400.0000\n",
      "Epoch 723/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 802544768.0000 - val_loss: 2803260672.0000\n",
      "Epoch 724/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 795061312.0000 - val_loss: 2753391872.0000\n",
      "Epoch 725/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 803783616.0000 - val_loss: 2776242176.0000\n",
      "Epoch 726/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 797733440.0000 - val_loss: 2824696320.0000\n",
      "Epoch 727/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 794902080.0000 - val_loss: 2806032384.0000\n",
      "Epoch 728/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 793976064.0000 - val_loss: 2841048320.0000\n",
      "Epoch 729/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 804377728.0000 - val_loss: 2759640064.0000\n",
      "Epoch 730/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 793996736.0000 - val_loss: 2844540416.0000\n",
      "Epoch 731/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 796824576.0000 - val_loss: 2794064128.0000\n",
      "Epoch 732/1500\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 796263552.0000 - val_loss: 2710642688.0000\n",
      "Epoch 733/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 788596096.0000 - val_loss: 2758094080.0000\n",
      "Epoch 734/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 784437056.0000 - val_loss: 2774767104.0000\n",
      "Epoch 735/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 789210304.0000 - val_loss: 2755478528.0000\n",
      "Epoch 736/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 794093568.0000 - val_loss: 2850332672.0000\n",
      "Epoch 737/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 779672320.0000 - val_loss: 2766874368.0000\n",
      "Epoch 738/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 783882624.0000 - val_loss: 2700017408.0000\n",
      "Epoch 739/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 799728576.0000 - val_loss: 2851806208.0000\n",
      "Epoch 740/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 798447744.0000 - val_loss: 2811953408.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 741/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 797859392.0000 - val_loss: 2814713600.0000\n",
      "Epoch 742/1500\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 791123584.0000 - val_loss: 2781031936.0000\n",
      "Epoch 743/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 795597632.0000 - val_loss: 2764518656.0000\n",
      "Epoch 744/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 788305536.0000 - val_loss: 2839099136.0000\n",
      "Epoch 745/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 781852992.0000 - val_loss: 2770573312.0000\n",
      "Epoch 746/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 792630208.0000 - val_loss: 2722238976.0000\n",
      "Epoch 747/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 777705408.0000 - val_loss: 2795533568.0000\n",
      "Epoch 748/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 787053440.0000 - val_loss: 2780433152.0000\n",
      "Epoch 749/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 771921536.0000 - val_loss: 2721329152.0000\n",
      "Epoch 750/1500\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 789773376.0000 - val_loss: 2776009472.0000\n",
      "Epoch 751/1500\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 784190720.0000 - val_loss: 2733374464.0000\n",
      "Epoch 752/1500\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 780075456.0000 - val_loss: 2736717312.0000\n",
      "Epoch 753/1500\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 775599680.0000 - val_loss: 2778453248.0000\n",
      "Epoch 754/1500\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 776722624.0000 - val_loss: 2809762048.0000\n",
      "Epoch 755/1500\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 779938432.0000 - val_loss: 2696428544.0000\n",
      "Epoch 756/1500\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 779868544.0000 - val_loss: 2806228480.0000\n",
      "Epoch 757/1500\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 779042560.0000 - val_loss: 2762481664.0000\n",
      "Epoch 758/1500\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 784327104.0000 - val_loss: 2678015744.0000\n",
      "Epoch 759/1500\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 772351872.0000 - val_loss: 2704283392.0000\n",
      "Epoch 760/1500\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 778654720.0000 - val_loss: 2683802112.0000\n",
      "Epoch 761/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 774103616.0000 - val_loss: 2821701120.0000\n",
      "Epoch 762/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 774987968.0000 - val_loss: 2733614848.0000\n",
      "Epoch 763/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 761465728.0000 - val_loss: 2797477376.0000\n",
      "Epoch 764/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 773631616.0000 - val_loss: 2651553536.0000\n",
      "Epoch 765/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 771996032.0000 - val_loss: 2758909952.0000\n",
      "Epoch 766/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 764635584.0000 - val_loss: 2717526272.0000\n",
      "Epoch 767/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 772851200.0000 - val_loss: 2725598976.0000\n",
      "Epoch 768/1500\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 772700352.0000 - val_loss: 2705059328.0000\n",
      "Epoch 769/1500\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 762438336.0000 - val_loss: 2647539200.0000\n",
      "Epoch 770/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 765262080.0000 - val_loss: 2754177024.0000\n",
      "Epoch 771/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 775002816.0000 - val_loss: 2701402624.0000\n",
      "Epoch 772/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 778575872.0000 - val_loss: 2705116160.0000\n",
      "Epoch 773/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 765171712.0000 - val_loss: 2711414016.0000\n",
      "Epoch 774/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 764780160.0000 - val_loss: 2697054464.0000\n",
      "Epoch 775/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 760377344.0000 - val_loss: 2629873920.0000\n",
      "Epoch 776/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 762958400.0000 - val_loss: 2862065664.0000\n",
      "Epoch 777/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 772796544.0000 - val_loss: 2676814080.0000\n",
      "Epoch 778/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 770637312.0000 - val_loss: 2789140224.0000\n",
      "Epoch 779/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 755939264.0000 - val_loss: 2701359616.0000\n",
      "Epoch 780/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 755175488.0000 - val_loss: 2785202432.0000\n",
      "Epoch 781/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 765810560.0000 - val_loss: 2648024320.0000\n",
      "Epoch 782/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 766862976.0000 - val_loss: 2696089344.0000\n",
      "Epoch 783/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 762827520.0000 - val_loss: 2673393664.0000\n",
      "Epoch 784/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 751280192.0000 - val_loss: 2701209344.0000\n",
      "Epoch 785/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 758223040.0000 - val_loss: 2660749568.0000\n",
      "Epoch 786/1500\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 760429312.0000 - val_loss: 2590988544.0000\n",
      "Epoch 787/1500\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 754360576.0000 - val_loss: 2653458944.0000\n",
      "Epoch 788/1500\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 750563392.0000 - val_loss: 2603687168.0000\n",
      "Epoch 789/1500\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 755072448.0000 - val_loss: 2584724480.0000\n",
      "Epoch 790/1500\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 755619008.0000 - val_loss: 2669512960.0000\n",
      "Epoch 791/1500\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 748045184.0000 - val_loss: 2642994432.0000\n",
      "Epoch 792/1500\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 747720128.0000 - val_loss: 2557618688.0000\n",
      "Epoch 793/1500\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 745884608.0000 - val_loss: 2595322112.0000\n",
      "Epoch 794/1500\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 746273984.0000 - val_loss: 2664886016.0000\n",
      "Epoch 795/1500\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 751020544.0000 - val_loss: 2630515968.0000\n",
      "Epoch 796/1500\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 760757440.0000 - val_loss: 2703971840.0000\n",
      "Epoch 797/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 748350080.0000 - val_loss: 2624490752.0000\n",
      "Epoch 798/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 740561152.0000 - val_loss: 2545636608.0000\n",
      "Epoch 799/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 747037952.0000 - val_loss: 2630583296.0000\n",
      "Epoch 800/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 747217088.0000 - val_loss: 2603284992.0000\n",
      "Epoch 801/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 741838272.0000 - val_loss: 2600520960.0000\n",
      "Epoch 802/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 761626176.0000 - val_loss: 2691130368.0000\n",
      "Epoch 803/1500\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 748084160.0000 - val_loss: 2692752896.0000\n",
      "Epoch 804/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 742826560.0000 - val_loss: 2519870720.0000\n",
      "Epoch 805/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 739434880.0000 - val_loss: 2613558272.0000\n",
      "Epoch 806/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 739840576.0000 - val_loss: 2674960896.0000\n",
      "Epoch 807/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 736911616.0000 - val_loss: 2534935296.0000\n",
      "Epoch 808/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "117/117 [==============================] - 0s 1ms/step - loss: 744345792.0000 - val_loss: 2640960768.0000\n",
      "Epoch 809/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 738781760.0000 - val_loss: 2522447360.0000\n",
      "Epoch 810/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 737954752.0000 - val_loss: 2573659648.0000\n",
      "Epoch 811/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 730377984.0000 - val_loss: 2571422208.0000\n",
      "Epoch 812/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 739871424.0000 - val_loss: 2542535680.0000\n",
      "Epoch 813/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 731558400.0000 - val_loss: 2589456384.0000\n",
      "Epoch 814/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 733665408.0000 - val_loss: 2681332480.0000\n",
      "Epoch 815/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 740404736.0000 - val_loss: 2638792192.0000\n",
      "Epoch 816/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 735369792.0000 - val_loss: 2564409344.0000\n",
      "Epoch 817/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 733684672.0000 - val_loss: 2580731136.0000\n",
      "Epoch 818/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 732328576.0000 - val_loss: 2570378496.0000\n",
      "Epoch 819/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 722469120.0000 - val_loss: 2501409536.0000\n",
      "Epoch 820/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 738430528.0000 - val_loss: 2497680896.0000\n",
      "Epoch 821/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 737611648.0000 - val_loss: 2527340032.0000\n",
      "Epoch 822/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 727403008.0000 - val_loss: 2501406464.0000\n",
      "Epoch 823/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 741863296.0000 - val_loss: 2527297792.0000\n",
      "Epoch 824/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 726756864.0000 - val_loss: 2503386624.0000\n",
      "Epoch 825/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 730135040.0000 - val_loss: 2485276672.0000\n",
      "Epoch 826/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 729292416.0000 - val_loss: 2516119552.0000\n",
      "Epoch 827/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 734102400.0000 - val_loss: 2477507072.0000\n",
      "Epoch 828/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 729393152.0000 - val_loss: 2463683072.0000\n",
      "Epoch 829/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 732088960.0000 - val_loss: 2500689664.0000\n",
      "Epoch 830/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 719336640.0000 - val_loss: 2494297344.0000\n",
      "Epoch 831/1500\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 725208704.0000 - val_loss: 2527427584.0000\n",
      "Epoch 832/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 726392832.0000 - val_loss: 2555682304.0000\n",
      "Epoch 833/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 726397632.0000 - val_loss: 2533081600.0000\n",
      "Epoch 834/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 726460032.0000 - val_loss: 2471716096.0000\n",
      "Epoch 835/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 720501824.0000 - val_loss: 2536503040.0000\n",
      "Epoch 836/1500\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 715299520.0000 - val_loss: 2527123968.0000\n",
      "Epoch 837/1500\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 732341824.0000 - val_loss: 2507647744.0000\n",
      "Epoch 838/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 719974848.0000 - val_loss: 2497045760.0000\n",
      "Epoch 839/1500\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 718330880.0000 - val_loss: 2516312064.0000\n",
      "Epoch 840/1500\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 728498944.0000 - val_loss: 2488327424.0000\n",
      "Epoch 841/1500\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 724765824.0000 - val_loss: 2431004672.0000\n",
      "Epoch 842/1500\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 709570496.0000 - val_loss: 2443381248.0000\n",
      "Epoch 843/1500\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 722149632.0000 - val_loss: 2538523904.0000\n",
      "Epoch 844/1500\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 717938880.0000 - val_loss: 2404695296.0000\n",
      "Epoch 845/1500\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 713099136.0000 - val_loss: 2453724416.0000\n",
      "Epoch 846/1500\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 712192384.0000 - val_loss: 2499283456.0000\n",
      "Epoch 847/1500\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 727966912.0000 - val_loss: 2428746496.0000\n",
      "Epoch 848/1500\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 720168960.0000 - val_loss: 2387552256.0000\n",
      "Epoch 849/1500\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 724578880.0000 - val_loss: 2545532672.0000\n",
      "Epoch 850/1500\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 723792768.0000 - val_loss: 2373634560.0000\n",
      "Epoch 851/1500\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 720808256.0000 - val_loss: 2539260672.0000\n",
      "Epoch 852/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 724046528.0000 - val_loss: 2528794624.0000\n",
      "Epoch 853/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 712817408.0000 - val_loss: 2542575616.0000\n",
      "Epoch 854/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 721148992.0000 - val_loss: 2457299968.0000\n",
      "Epoch 855/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 716606592.0000 - val_loss: 2509602816.0000\n",
      "Epoch 856/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 706307840.0000 - val_loss: 2384731136.0000\n",
      "Epoch 857/1500\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 707184832.0000 - val_loss: 2395664128.0000\n",
      "Epoch 858/1500\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 710908928.0000 - val_loss: 2376628224.0000\n",
      "Epoch 859/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 701682176.0000 - val_loss: 2368749312.0000\n",
      "Epoch 860/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 704693056.0000 - val_loss: 2331107328.0000\n",
      "Epoch 861/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 713749376.0000 - val_loss: 2484526336.0000\n",
      "Epoch 862/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 719669440.0000 - val_loss: 2453124352.0000\n",
      "Epoch 863/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 700059136.0000 - val_loss: 2657349120.0000\n",
      "Epoch 864/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 707942848.0000 - val_loss: 2424839680.0000\n",
      "Epoch 865/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 698933760.0000 - val_loss: 2413464064.0000\n",
      "Epoch 866/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 713444224.0000 - val_loss: 2388323072.0000\n",
      "Epoch 867/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 701378816.0000 - val_loss: 2337761024.0000\n",
      "Epoch 868/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 706893056.0000 - val_loss: 2465832704.0000\n",
      "Epoch 869/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 696097856.0000 - val_loss: 2364986880.0000\n",
      "Epoch 870/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 705348608.0000 - val_loss: 2396552192.0000\n",
      "Epoch 871/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 694379072.0000 - val_loss: 2353137664.0000\n",
      "Epoch 872/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 704517888.0000 - val_loss: 2396058368.0000\n",
      "Epoch 873/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 690086400.0000 - val_loss: 2424508160.0000\n",
      "Epoch 874/1500\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 693273472.0000 - val_loss: 2330376448.0000\n",
      "Epoch 875/1500\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 697883008.0000 - val_loss: 2329362688.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 876/1500\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 692541120.0000 - val_loss: 2374133248.0000\n",
      "Epoch 877/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 703194688.0000 - val_loss: 2357898752.0000\n",
      "Epoch 878/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 689248320.0000 - val_loss: 2403713536.0000\n",
      "Epoch 879/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 706122624.0000 - val_loss: 2351929600.0000\n",
      "Epoch 880/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 692235776.0000 - val_loss: 2320370432.0000\n",
      "Epoch 881/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 706699776.0000 - val_loss: 2387955200.0000\n",
      "Epoch 882/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 701213568.0000 - val_loss: 2326822656.0000\n",
      "Epoch 883/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 704896576.0000 - val_loss: 2326716416.0000\n",
      "Epoch 884/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 684352768.0000 - val_loss: 2289683200.0000\n",
      "Epoch 885/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 699378752.0000 - val_loss: 2307758592.0000\n",
      "Epoch 886/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 690910528.0000 - val_loss: 2317757440.0000\n",
      "Epoch 887/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 695845760.0000 - val_loss: 2337135616.0000\n",
      "Epoch 888/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 702863808.0000 - val_loss: 2347987968.0000\n",
      "Epoch 889/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 692533120.0000 - val_loss: 2351503616.0000\n",
      "Epoch 890/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 690858432.0000 - val_loss: 2277899776.0000\n",
      "Epoch 891/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 686831360.0000 - val_loss: 2315187712.0000\n",
      "Epoch 892/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 693228608.0000 - val_loss: 2279766528.0000\n",
      "Epoch 893/1500\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 690668096.0000 - val_loss: 2364252928.0000\n",
      "Epoch 894/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 689220352.0000 - val_loss: 2361261056.0000\n",
      "Epoch 895/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 694805248.0000 - val_loss: 2312587008.0000\n",
      "Epoch 896/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 687517696.0000 - val_loss: 2272228352.0000\n",
      "Epoch 897/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 682880256.0000 - val_loss: 2364081920.0000\n",
      "Epoch 898/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 683854656.0000 - val_loss: 2280945664.0000\n",
      "Epoch 899/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 693538816.0000 - val_loss: 2347556096.0000\n",
      "Epoch 900/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 676450240.0000 - val_loss: 2253931008.0000\n",
      "Epoch 901/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 686645440.0000 - val_loss: 2288947712.0000\n",
      "Epoch 902/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 680533824.0000 - val_loss: 2307834112.0000\n",
      "Epoch 903/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 678963840.0000 - val_loss: 2388772864.0000\n",
      "Epoch 904/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 675714432.0000 - val_loss: 2280480256.0000\n",
      "Epoch 905/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 679763008.0000 - val_loss: 2329852928.0000\n",
      "Epoch 906/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 685507904.0000 - val_loss: 2265180160.0000\n",
      "Epoch 907/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 687703616.0000 - val_loss: 2268472064.0000\n",
      "Epoch 908/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 677038272.0000 - val_loss: 2317943808.0000\n",
      "Epoch 909/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 672183616.0000 - val_loss: 2281597184.0000\n",
      "Epoch 910/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 673633536.0000 - val_loss: 2288691712.0000\n",
      "Epoch 911/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 674249216.0000 - val_loss: 2360943104.0000\n",
      "Epoch 912/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 673001024.0000 - val_loss: 2340806400.0000\n",
      "Epoch 913/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 675509312.0000 - val_loss: 2298507264.0000\n",
      "Epoch 914/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 671120960.0000 - val_loss: 2255659776.0000\n",
      "Epoch 915/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 676235136.0000 - val_loss: 2269750528.0000\n",
      "Epoch 916/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 673377600.0000 - val_loss: 2316439552.0000\n",
      "Epoch 917/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 681268928.0000 - val_loss: 2332076800.0000\n",
      "Epoch 918/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 674947136.0000 - val_loss: 2304029952.0000\n",
      "Epoch 919/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 662783424.0000 - val_loss: 2254248448.0000\n",
      "Epoch 920/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 670443520.0000 - val_loss: 2357988352.0000\n",
      "Epoch 921/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 666819392.0000 - val_loss: 2277663232.0000\n",
      "Epoch 922/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 670534784.0000 - val_loss: 2300316928.0000\n",
      "Epoch 923/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 674674624.0000 - val_loss: 2259423744.0000\n",
      "Epoch 924/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 676422720.0000 - val_loss: 2361415424.0000\n",
      "Epoch 925/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 659733568.0000 - val_loss: 2293180672.0000\n",
      "Epoch 926/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 666282496.0000 - val_loss: 2186740992.0000\n",
      "Epoch 927/1500\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 673811136.0000 - val_loss: 2395015680.0000\n",
      "Epoch 928/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 661439488.0000 - val_loss: 2243678464.0000\n",
      "Epoch 929/1500\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 659447232.0000 - val_loss: 2276058112.0000\n",
      "Epoch 930/1500\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 673064768.0000 - val_loss: 2165051392.0000\n",
      "Epoch 931/1500\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 670099264.0000 - val_loss: 2215548928.0000\n",
      "Epoch 932/1500\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 673692160.0000 - val_loss: 2222543104.0000\n",
      "Epoch 933/1500\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 669445312.0000 - val_loss: 2276710656.0000\n",
      "Epoch 934/1500\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 682756544.0000 - val_loss: 2324332544.0000\n",
      "Epoch 935/1500\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 658160960.0000 - val_loss: 2256419840.0000\n",
      "Epoch 936/1500\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 662619136.0000 - val_loss: 2197907968.0000\n",
      "Epoch 937/1500\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 663468160.0000 - val_loss: 2211392768.0000\n",
      "Epoch 938/1500\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 652091584.0000 - val_loss: 2281296384.0000\n",
      "Epoch 939/1500\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 664917568.0000 - val_loss: 2213747712.0000\n",
      "Epoch 940/1500\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 656681472.0000 - val_loss: 2272726784.0000\n",
      "Epoch 941/1500\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 661704192.0000 - val_loss: 2245414656.0000\n",
      "Epoch 942/1500\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 659086144.0000 - val_loss: 2218414080.0000\n",
      "Epoch 943/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "117/117 [==============================] - 0s 2ms/step - loss: 667433600.0000 - val_loss: 2298922496.0000\n",
      "Epoch 944/1500\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 664175488.0000 - val_loss: 2207003648.0000\n",
      "Epoch 945/1500\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 653420352.0000 - val_loss: 2296302080.0000\n",
      "Epoch 946/1500\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 658936000.0000 - val_loss: 2305304320.0000\n",
      "Epoch 947/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 658343232.0000 - val_loss: 2167010048.0000\n",
      "Epoch 948/1500\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 665199104.0000 - val_loss: 2213294080.0000\n",
      "Epoch 949/1500\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 652258688.0000 - val_loss: 2198706432.0000\n",
      "Epoch 950/1500\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 648164288.0000 - val_loss: 2111341056.0000\n",
      "Epoch 951/1500\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 667483904.0000 - val_loss: 2192363520.0000\n",
      "Epoch 952/1500\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 658518080.0000 - val_loss: 2226379008.0000\n",
      "Epoch 953/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 649471168.0000 - val_loss: 2231120896.0000\n",
      "Epoch 954/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 651940608.0000 - val_loss: 2186405632.0000\n",
      "Epoch 955/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 653657088.0000 - val_loss: 2183905280.0000\n",
      "Epoch 956/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 646172224.0000 - val_loss: 2165317632.0000\n",
      "Epoch 957/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 644871488.0000 - val_loss: 2170144768.0000\n",
      "Epoch 958/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 661782272.0000 - val_loss: 2163109376.0000\n",
      "Epoch 959/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 648180032.0000 - val_loss: 2104256384.0000\n",
      "Epoch 960/1500\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 644724608.0000 - val_loss: 2186968064.0000\n",
      "Epoch 961/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 650893376.0000 - val_loss: 2225743872.0000\n",
      "Epoch 962/1500\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 647726464.0000 - val_loss: 2138495104.0000\n",
      "Epoch 963/1500\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 650191808.0000 - val_loss: 2149314048.0000\n",
      "Epoch 964/1500\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 650045568.0000 - val_loss: 2146781568.0000\n",
      "Epoch 965/1500\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 652078272.0000 - val_loss: 2146499072.0000\n",
      "Epoch 966/1500\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 643017856.0000 - val_loss: 2207828224.0000\n",
      "Epoch 967/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 653179008.0000 - val_loss: 2174865920.0000\n",
      "Epoch 968/1500\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 652339648.0000 - val_loss: 2203651328.0000\n",
      "Epoch 969/1500\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 650674432.0000 - val_loss: 2160762624.0000\n",
      "Epoch 970/1500\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 651659008.0000 - val_loss: 2123676288.0000\n",
      "Epoch 971/1500\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 649256448.0000 - val_loss: 2099358720.0000\n",
      "Epoch 972/1500\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 649638400.0000 - val_loss: 2143415424.0000\n",
      "Epoch 973/1500\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 639542144.0000 - val_loss: 2199590400.0000\n",
      "Epoch 974/1500\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 648502080.0000 - val_loss: 2084272640.0000\n",
      "Epoch 975/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 645787712.0000 - val_loss: 2092998272.0000\n",
      "Epoch 976/1500\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 646480192.0000 - val_loss: 2176026880.0000\n",
      "Epoch 977/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 633790272.0000 - val_loss: 2035554688.0000\n",
      "Epoch 978/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 639760320.0000 - val_loss: 2165969152.0000\n",
      "Epoch 979/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 644021120.0000 - val_loss: 2082841984.0000\n",
      "Epoch 980/1500\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 647880448.0000 - val_loss: 2104816384.0000\n",
      "Epoch 981/1500\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 645553344.0000 - val_loss: 2096136704.0000\n",
      "Epoch 982/1500\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 630324288.0000 - val_loss: 2094820480.0000\n",
      "Epoch 983/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 637881728.0000 - val_loss: 2143879168.0000\n",
      "Epoch 984/1500\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 648213312.0000 - val_loss: 2070534784.0000\n",
      "Epoch 985/1500\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 627017728.0000 - val_loss: 2074052992.0000\n",
      "Epoch 986/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 650586176.0000 - val_loss: 2086022272.0000\n",
      "Epoch 987/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 632919232.0000 - val_loss: 2216837120.0000\n",
      "Epoch 988/1500\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 641684864.0000 - val_loss: 2062334464.0000\n",
      "Epoch 989/1500\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 651598656.0000 - val_loss: 2282230528.0000\n",
      "Epoch 990/1500\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 629354304.0000 - val_loss: 2147369856.0000\n",
      "Epoch 991/1500\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 635618240.0000 - val_loss: 2088867072.0000\n",
      "Epoch 992/1500\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 636358720.0000 - val_loss: 2277603072.0000\n",
      "Epoch 993/1500\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 631831104.0000 - val_loss: 2087138944.0000\n",
      "Epoch 994/1500\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 632417856.0000 - val_loss: 2104158976.0000\n",
      "Epoch 995/1500\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 625143808.0000 - val_loss: 2101062144.0000\n",
      "Epoch 996/1500\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 623955008.0000 - val_loss: 2137223680.0000\n",
      "Epoch 997/1500\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 623960960.0000 - val_loss: 2110960128.0000\n",
      "Epoch 998/1500\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 636768000.0000 - val_loss: 2093654144.0000\n",
      "Epoch 999/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 639387712.0000 - val_loss: 2116647168.0000\n",
      "Epoch 1000/1500\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 632235648.0000 - val_loss: 2046774144.0000\n",
      "Epoch 1001/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 627618368.0000 - val_loss: 2098997120.0000\n",
      "Epoch 1002/1500\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 619097280.0000 - val_loss: 2153779712.0000\n",
      "Epoch 1003/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 635213184.0000 - val_loss: 1993591040.0000\n",
      "Epoch 1004/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 625493952.0000 - val_loss: 2143742976.0000\n",
      "Epoch 1005/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 623776832.0000 - val_loss: 2020029824.0000\n",
      "Epoch 1006/1500\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 625805120.0000 - val_loss: 2005255936.0000\n",
      "Epoch 1007/1500\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 621290176.0000 - val_loss: 1991198720.0000\n",
      "Epoch 1008/1500\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 624705472.0000 - val_loss: 2027867008.0000\n",
      "Epoch 1009/1500\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 625944640.0000 - val_loss: 1982550400.0000\n",
      "Epoch 1010/1500\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 626627328.0000 - val_loss: 2071113344.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1011/1500\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 619013056.0000 - val_loss: 2040847872.0000\n",
      "Epoch 1012/1500\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 617963008.0000 - val_loss: 2113570176.0000\n",
      "Epoch 1013/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 614530752.0000 - val_loss: 2175860992.0000\n",
      "Epoch 1014/1500\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 628265088.0000 - val_loss: 1981799936.0000\n",
      "Epoch 1015/1500\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 621622336.0000 - val_loss: 2042439040.0000\n",
      "Epoch 1016/1500\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 620628544.0000 - val_loss: 2044430720.0000\n",
      "Epoch 1017/1500\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 617946944.0000 - val_loss: 2043702912.0000\n",
      "Epoch 1018/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 620810368.0000 - val_loss: 2076862336.0000\n",
      "Epoch 1019/1500\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 623411200.0000 - val_loss: 2042314496.0000\n",
      "Epoch 1020/1500\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 623915840.0000 - val_loss: 2074177408.0000\n",
      "Epoch 1021/1500\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 619535232.0000 - val_loss: 2081196672.0000\n",
      "Epoch 1022/1500\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 609262784.0000 - val_loss: 2122246272.0000\n",
      "Epoch 1023/1500\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 620281024.0000 - val_loss: 2049831424.0000\n",
      "Epoch 1024/1500\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 622587712.0000 - val_loss: 2050172800.0000\n",
      "Epoch 1025/1500\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 620982720.0000 - val_loss: 2003050112.0000\n",
      "Epoch 1026/1500\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 623303616.0000 - val_loss: 2085122048.0000\n",
      "Epoch 1027/1500\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 628059456.0000 - val_loss: 2071367680.0000\n",
      "Epoch 1028/1500\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 619135232.0000 - val_loss: 1983913472.0000\n",
      "Epoch 1029/1500\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 607441472.0000 - val_loss: 2006976000.0000\n",
      "Epoch 1030/1500\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 604071424.0000 - val_loss: 2022998016.0000\n",
      "Epoch 1031/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 596510464.0000 - val_loss: 2020747520.0000\n",
      "Epoch 1032/1500\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 612391872.0000 - val_loss: 2031921280.0000\n",
      "Epoch 1033/1500\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 608751040.0000 - val_loss: 1932959360.0000\n",
      "Epoch 1034/1500\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 631084800.0000 - val_loss: 2063599616.0000\n",
      "Epoch 1035/1500\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 610168320.0000 - val_loss: 2025289344.0000\n",
      "Epoch 1036/1500\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 616537536.0000 - val_loss: 1944195968.0000\n",
      "Epoch 1037/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 609391616.0000 - val_loss: 2072660864.0000\n",
      "Epoch 1038/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 608561920.0000 - val_loss: 2062910336.0000\n",
      "Epoch 1039/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 603852544.0000 - val_loss: 2030268672.0000\n",
      "Epoch 1040/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 619661248.0000 - val_loss: 1997796992.0000\n",
      "Epoch 1041/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 613855616.0000 - val_loss: 1990078080.0000\n",
      "Epoch 1042/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 598924352.0000 - val_loss: 2057948416.0000\n",
      "Epoch 1043/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 595235200.0000 - val_loss: 2055023616.0000\n",
      "Epoch 1044/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 618199616.0000 - val_loss: 1983743104.0000\n",
      "Epoch 1045/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 604242752.0000 - val_loss: 2103170816.0000\n",
      "Epoch 1046/1500\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 614470528.0000 - val_loss: 2064293760.0000\n",
      "Epoch 1047/1500\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 616705408.0000 - val_loss: 1942830592.0000\n",
      "Epoch 1048/1500\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 598977216.0000 - val_loss: 2066155264.0000\n",
      "Epoch 1049/1500\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 602607744.0000 - val_loss: 1988079616.0000\n",
      "Epoch 1050/1500\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 599859776.0000 - val_loss: 1963698048.0000\n",
      "Epoch 1051/1500\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 611073024.0000 - val_loss: 2038879488.0000\n",
      "Epoch 1052/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 614441664.0000 - val_loss: 2029412480.0000\n",
      "Epoch 1053/1500\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 609626368.0000 - val_loss: 2005223424.0000\n",
      "Epoch 1054/1500\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 605891840.0000 - val_loss: 1978312960.0000\n",
      "Epoch 1055/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 597752384.0000 - val_loss: 1969526016.0000\n",
      "Epoch 1056/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 601403008.0000 - val_loss: 2115782400.0000\n",
      "Epoch 1057/1500\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 598680320.0000 - val_loss: 1906093184.0000\n",
      "Epoch 1058/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 614322880.0000 - val_loss: 1923468800.0000\n",
      "Epoch 1059/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 600278656.0000 - val_loss: 2032390144.0000\n",
      "Epoch 1060/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 602715648.0000 - val_loss: 2000732160.0000\n",
      "Epoch 1061/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 589830528.0000 - val_loss: 1969121536.0000\n",
      "Epoch 1062/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 601342656.0000 - val_loss: 1961871360.0000\n",
      "Epoch 1063/1500\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 604635392.0000 - val_loss: 1941353856.0000\n",
      "Epoch 1064/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 600357888.0000 - val_loss: 1873233280.0000\n",
      "Epoch 1065/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 598100736.0000 - val_loss: 1938594432.0000\n",
      "Epoch 1066/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 596053376.0000 - val_loss: 1930440320.0000\n",
      "Epoch 1067/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 592443648.0000 - val_loss: 1936933120.0000\n",
      "Epoch 1068/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 592210496.0000 - val_loss: 2073964800.0000\n",
      "Epoch 1069/1500\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 598875264.0000 - val_loss: 2061493504.0000\n",
      "Epoch 1070/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 588976384.0000 - val_loss: 2052169600.0000\n",
      "Epoch 1071/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 590910208.0000 - val_loss: 1900269312.0000\n",
      "Epoch 1072/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 598495744.0000 - val_loss: 1944154880.0000\n",
      "Epoch 1073/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 588386496.0000 - val_loss: 2003130496.0000\n",
      "Epoch 1074/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 606741248.0000 - val_loss: 1955703808.0000\n",
      "Epoch 1075/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 587529600.0000 - val_loss: 2013147904.0000\n",
      "Epoch 1076/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 582602368.0000 - val_loss: 1883377664.0000\n",
      "Epoch 1077/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 594980672.0000 - val_loss: 1867295360.0000\n",
      "Epoch 1078/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "117/117 [==============================] - 0s 1ms/step - loss: 598696320.0000 - val_loss: 1946034688.0000\n",
      "Epoch 1079/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 583426304.0000 - val_loss: 1949988480.0000\n",
      "Epoch 1080/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 601449728.0000 - val_loss: 2021740288.0000\n",
      "Epoch 1081/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 590347136.0000 - val_loss: 1900032512.0000\n",
      "Epoch 1082/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 594059648.0000 - val_loss: 1921070464.0000\n",
      "Epoch 1083/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 575129280.0000 - val_loss: 1900521344.0000\n",
      "Epoch 1084/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 590971456.0000 - val_loss: 1921900032.0000\n",
      "Epoch 1085/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 590003456.0000 - val_loss: 1995691776.0000\n",
      "Epoch 1086/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 584113280.0000 - val_loss: 1913165568.0000\n",
      "Epoch 1087/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 591260160.0000 - val_loss: 1878215168.0000\n",
      "Epoch 1088/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 595823488.0000 - val_loss: 1869702784.0000\n",
      "Epoch 1089/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 592833536.0000 - val_loss: 1963889536.0000\n",
      "Epoch 1090/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 587299840.0000 - val_loss: 1907328384.0000\n",
      "Epoch 1091/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 577542912.0000 - val_loss: 1959261568.0000\n",
      "Epoch 1092/1500\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 582244160.0000 - val_loss: 1906404736.0000\n",
      "Epoch 1093/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 605445824.0000 - val_loss: 1895081600.0000\n",
      "Epoch 1094/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 583960768.0000 - val_loss: 2029839616.0000\n",
      "Epoch 1095/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 590354240.0000 - val_loss: 1876679168.0000\n",
      "Epoch 1096/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 586489344.0000 - val_loss: 1893048192.0000\n",
      "Epoch 1097/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 583210112.0000 - val_loss: 1820463488.0000\n",
      "Epoch 1098/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 583833152.0000 - val_loss: 1884308096.0000\n",
      "Epoch 1099/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 590707264.0000 - val_loss: 2001226880.0000\n",
      "Epoch 1100/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 577086080.0000 - val_loss: 1881710080.0000\n",
      "Epoch 1101/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 596135872.0000 - val_loss: 1932303872.0000\n",
      "Epoch 1102/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 586388992.0000 - val_loss: 1884559232.0000\n",
      "Epoch 1103/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 584006912.0000 - val_loss: 1900131072.0000\n",
      "Epoch 1104/1500\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 597187968.0000 - val_loss: 1885006592.0000\n",
      "Epoch 1105/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 572449472.0000 - val_loss: 1853906560.0000\n",
      "Epoch 1106/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 584390784.0000 - val_loss: 1964432640.0000\n",
      "Epoch 1107/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 596341504.0000 - val_loss: 1872655360.0000\n",
      "Epoch 1108/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 577640832.0000 - val_loss: 1912459648.0000\n",
      "Epoch 1109/1500\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 578077184.0000 - val_loss: 1909830400.0000\n",
      "Epoch 1110/1500\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 588790080.0000 - val_loss: 1962479104.0000\n",
      "Epoch 1111/1500\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 593116608.0000 - val_loss: 1909871616.0000\n",
      "Epoch 1112/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 582023872.0000 - val_loss: 1907203328.0000\n",
      "Epoch 1113/1500\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 567247744.0000 - val_loss: 1889609088.0000\n",
      "Epoch 1114/1500\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 574271552.0000 - val_loss: 1923451264.0000\n",
      "Epoch 1115/1500\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 583378304.0000 - val_loss: 1897863040.0000\n",
      "Epoch 1116/1500\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 578662208.0000 - val_loss: 1868041984.0000\n",
      "Epoch 1117/1500\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 584700736.0000 - val_loss: 1933402880.0000\n",
      "Epoch 1118/1500\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 571145728.0000 - val_loss: 1831840000.0000\n",
      "Epoch 1119/1500\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 559559168.0000 - val_loss: 1872790400.0000\n",
      "Epoch 1120/1500\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 589724800.0000 - val_loss: 1824407680.0000\n",
      "Epoch 1121/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 566989760.0000 - val_loss: 1891280512.0000\n",
      "Epoch 1122/1500\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 568634560.0000 - val_loss: 1850251904.0000\n",
      "Epoch 1123/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 561472640.0000 - val_loss: 1844336384.0000\n",
      "Epoch 1124/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 567963584.0000 - val_loss: 1838241536.0000\n",
      "Epoch 1125/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 565791936.0000 - val_loss: 1855236224.0000\n",
      "Epoch 1126/1500\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 568991936.0000 - val_loss: 1936027904.0000\n",
      "Epoch 1127/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 569312000.0000 - val_loss: 1808409984.0000\n",
      "Epoch 1128/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 560834304.0000 - val_loss: 1936554240.0000\n",
      "Epoch 1129/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 568707328.0000 - val_loss: 1842783104.0000\n",
      "Epoch 1130/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 576324992.0000 - val_loss: 1832804864.0000\n",
      "Epoch 1131/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 570405440.0000 - val_loss: 1819682048.0000\n",
      "Epoch 1132/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 602147200.0000 - val_loss: 1851799424.0000\n",
      "Epoch 1133/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 587248128.0000 - val_loss: 1818044160.0000\n",
      "Epoch 1134/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 573964544.0000 - val_loss: 1794771200.0000\n",
      "Epoch 1135/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 573174848.0000 - val_loss: 1881439360.0000\n",
      "Epoch 1136/1500\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 560713600.0000 - val_loss: 1846449920.0000\n",
      "Epoch 1137/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 570890048.0000 - val_loss: 1854443904.0000\n",
      "Epoch 1138/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 563805440.0000 - val_loss: 1904776960.0000\n",
      "Epoch 1139/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 573126272.0000 - val_loss: 1876421120.0000\n",
      "Epoch 1140/1500\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 558246720.0000 - val_loss: 1828756608.0000\n",
      "Epoch 1141/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 564174912.0000 - val_loss: 1859658240.0000\n",
      "Epoch 1142/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 555794560.0000 - val_loss: 1822270208.0000\n",
      "Epoch 1143/1500\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 569318912.0000 - val_loss: 1863219200.0000\n",
      "Epoch 1144/1500\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 572245440.0000 - val_loss: 1810462464.0000\n",
      "Epoch 1145/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "117/117 [==============================] - 0s 1ms/step - loss: 547406400.0000 - val_loss: 1970596992.0000\n",
      "Epoch 1146/1500\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 556910336.0000 - val_loss: 1801656064.0000\n",
      "Epoch 1147/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 559140544.0000 - val_loss: 1855107712.0000\n",
      "Epoch 1148/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 557683712.0000 - val_loss: 1795952128.0000\n",
      "Epoch 1149/1500\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 553084160.0000 - val_loss: 1936142592.0000\n",
      "Epoch 1150/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 550552704.0000 - val_loss: 1876747648.0000\n",
      "Epoch 1151/1500\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 557511744.0000 - val_loss: 1879274880.0000\n",
      "Epoch 1152/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 562083904.0000 - val_loss: 1838170624.0000\n",
      "Epoch 1153/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 568869760.0000 - val_loss: 1857962880.0000\n",
      "Epoch 1154/1500\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 554871360.0000 - val_loss: 1807330304.0000\n",
      "Epoch 1155/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 558600704.0000 - val_loss: 1806277376.0000\n",
      "Epoch 1156/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 547722624.0000 - val_loss: 1887625600.0000\n",
      "Epoch 1157/1500\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 553824768.0000 - val_loss: 1888349312.0000\n",
      "Epoch 1158/1500\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 557420544.0000 - val_loss: 1756827264.0000\n",
      "Epoch 1159/1500\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 554060160.0000 - val_loss: 1788546048.0000\n",
      "Epoch 1160/1500\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 562218496.0000 - val_loss: 1797494784.0000\n",
      "Epoch 1161/1500\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 545055360.0000 - val_loss: 1828041216.0000\n",
      "Epoch 1162/1500\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 560288576.0000 - val_loss: 1867530368.0000\n",
      "Epoch 1163/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 564849984.0000 - val_loss: 1756921728.0000\n",
      "Epoch 1164/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 547781568.0000 - val_loss: 1791418880.0000\n",
      "Epoch 1165/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 556238720.0000 - val_loss: 1814983424.0000\n",
      "Epoch 1166/1500\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 550991936.0000 - val_loss: 1826270592.0000\n",
      "Epoch 1167/1500\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 555454272.0000 - val_loss: 1777808512.0000\n",
      "Epoch 1168/1500\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 550810176.0000 - val_loss: 1888766848.0000\n",
      "Epoch 1169/1500\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 537684352.0000 - val_loss: 1787049856.0000\n",
      "Epoch 1170/1500\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 544209152.0000 - val_loss: 1811285760.0000\n",
      "Epoch 1171/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 553396800.0000 - val_loss: 1760951424.0000\n",
      "Epoch 1172/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 539605760.0000 - val_loss: 1932090368.0000\n",
      "Epoch 1173/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 542017792.0000 - val_loss: 1866640128.0000\n",
      "Epoch 1174/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 551022592.0000 - val_loss: 1854336000.0000\n",
      "Epoch 1175/1500\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 548292480.0000 - val_loss: 1858929792.0000\n",
      "Epoch 1176/1500\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 553225344.0000 - val_loss: 1805912576.0000\n",
      "Epoch 1177/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 530101152.0000 - val_loss: 1743498368.0000\n",
      "Epoch 1178/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 558737920.0000 - val_loss: 1761371392.0000\n",
      "Epoch 1179/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 535853600.0000 - val_loss: 1767411456.0000\n",
      "Epoch 1180/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 559508928.0000 - val_loss: 1774292992.0000\n",
      "Epoch 1181/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 551495424.0000 - val_loss: 1889160320.0000\n",
      "Epoch 1182/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 543327488.0000 - val_loss: 1840288256.0000\n",
      "Epoch 1183/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 543664576.0000 - val_loss: 1789606784.0000\n",
      "Epoch 1184/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 544730304.0000 - val_loss: 1835943296.0000\n",
      "Epoch 1185/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 545252672.0000 - val_loss: 1766028544.0000\n",
      "Epoch 1186/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 544055232.0000 - val_loss: 1817721472.0000\n",
      "Epoch 1187/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 526041184.0000 - val_loss: 1743333504.0000\n",
      "Epoch 1188/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 546156096.0000 - val_loss: 1772939008.0000\n",
      "Epoch 1189/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 531557056.0000 - val_loss: 1775147264.0000\n",
      "Epoch 1190/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 535110752.0000 - val_loss: 1798109184.0000\n",
      "Epoch 1191/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 542043584.0000 - val_loss: 1749088896.0000\n",
      "Epoch 1192/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 533057920.0000 - val_loss: 1810166272.0000\n",
      "Epoch 1193/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 538791616.0000 - val_loss: 1740023168.0000\n",
      "Epoch 1194/1500\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 538720832.0000 - val_loss: 1795399168.0000\n",
      "Epoch 1195/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 530993856.0000 - val_loss: 1742067072.0000\n",
      "Epoch 1196/1500\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 528862208.0000 - val_loss: 1761091456.0000\n",
      "Epoch 1197/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 534570752.0000 - val_loss: 1726419328.0000\n",
      "Epoch 1198/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 544506816.0000 - val_loss: 1772931712.0000\n",
      "Epoch 1199/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 542479360.0000 - val_loss: 1791734656.0000\n",
      "Epoch 1200/1500\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 540392640.0000 - val_loss: 1832558720.0000\n",
      "Epoch 1201/1500\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 541923392.0000 - val_loss: 1733172864.0000\n",
      "Epoch 1202/1500\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 525723328.0000 - val_loss: 1795944448.0000\n",
      "Epoch 1203/1500\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 526419424.0000 - val_loss: 1775380736.0000\n",
      "Epoch 1204/1500\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 536251328.0000 - val_loss: 1756531712.0000\n",
      "Epoch 1205/1500\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 530881184.0000 - val_loss: 1760597376.0000\n",
      "Epoch 1206/1500\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 551065856.0000 - val_loss: 1749636096.0000\n",
      "Epoch 1207/1500\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 527313152.0000 - val_loss: 1703374848.0000\n",
      "Epoch 1208/1500\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 531320448.0000 - val_loss: 1898649472.0000\n",
      "Epoch 1209/1500\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 541537792.0000 - val_loss: 1811665920.0000\n",
      "Epoch 1210/1500\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 545598976.0000 - val_loss: 1770392192.0000\n",
      "Epoch 1211/1500\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 530201632.0000 - val_loss: 1732713088.0000\n",
      "Epoch 1212/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "117/117 [==============================] - 0s 1ms/step - loss: 530441760.0000 - val_loss: 1736105856.0000\n",
      "Epoch 1213/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 529945376.0000 - val_loss: 1764436352.0000\n",
      "Epoch 1214/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 522382976.0000 - val_loss: 1714136832.0000\n",
      "Epoch 1215/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 538504576.0000 - val_loss: 1717800960.0000\n",
      "Epoch 1216/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 527241728.0000 - val_loss: 1747991808.0000\n",
      "Epoch 1217/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 524698912.0000 - val_loss: 1769880448.0000\n",
      "Epoch 1218/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 532033888.0000 - val_loss: 1785934720.0000\n",
      "Epoch 1219/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 534342144.0000 - val_loss: 1747946112.0000\n",
      "Epoch 1220/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 533796448.0000 - val_loss: 1781980800.0000\n",
      "Epoch 1221/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 534694016.0000 - val_loss: 1780144512.0000\n",
      "Epoch 1222/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 532117440.0000 - val_loss: 1798428416.0000\n",
      "Epoch 1223/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 520780160.0000 - val_loss: 1685651584.0000\n",
      "Epoch 1224/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 525643040.0000 - val_loss: 1718314368.0000\n",
      "Epoch 1225/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 529523424.0000 - val_loss: 1706801920.0000\n",
      "Epoch 1226/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 533036256.0000 - val_loss: 1691983232.0000\n",
      "Epoch 1227/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 532598816.0000 - val_loss: 1733406592.0000\n",
      "Epoch 1228/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 520058144.0000 - val_loss: 1747639936.0000\n",
      "Epoch 1229/1500\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 519335808.0000 - val_loss: 1750970368.0000\n",
      "Epoch 1230/1500\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 525720352.0000 - val_loss: 1690030976.0000\n",
      "Epoch 1231/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 528234592.0000 - val_loss: 1692813312.0000\n",
      "Epoch 1232/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 524415968.0000 - val_loss: 1714509952.0000\n",
      "Epoch 1233/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 522967552.0000 - val_loss: 1704138496.0000\n",
      "Epoch 1234/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 535935424.0000 - val_loss: 1872044544.0000\n",
      "Epoch 1235/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 522328000.0000 - val_loss: 1679887872.0000\n",
      "Epoch 1236/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 529683616.0000 - val_loss: 1716547200.0000\n",
      "Epoch 1237/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 516819488.0000 - val_loss: 1640738816.0000\n",
      "Epoch 1238/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 538448832.0000 - val_loss: 1725050368.0000\n",
      "Epoch 1239/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 515141216.0000 - val_loss: 1755209472.0000\n",
      "Epoch 1240/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 530689536.0000 - val_loss: 1688736640.0000\n",
      "Epoch 1241/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 507973984.0000 - val_loss: 1734891264.0000\n",
      "Epoch 1242/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 525639424.0000 - val_loss: 1821591296.0000\n",
      "Epoch 1243/1500\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 512030400.0000 - val_loss: 1694068864.0000\n",
      "Epoch 1244/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 518601312.0000 - val_loss: 1753126784.0000\n",
      "Epoch 1245/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 516042944.0000 - val_loss: 1734436608.0000\n",
      "Epoch 1246/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 523715360.0000 - val_loss: 1725376384.0000\n",
      "Epoch 1247/1500\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 515306688.0000 - val_loss: 1727651968.0000\n",
      "Epoch 1248/1500\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 509463616.0000 - val_loss: 1766667136.0000\n",
      "Epoch 1249/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 518971616.0000 - val_loss: 1679449216.0000\n",
      "Epoch 1250/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 517255136.0000 - val_loss: 1752522240.0000\n",
      "Epoch 1251/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 535004576.0000 - val_loss: 1692851072.0000\n",
      "Epoch 1252/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 509778080.0000 - val_loss: 1815682944.0000\n",
      "Epoch 1253/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 512357760.0000 - val_loss: 1701424896.0000\n",
      "Epoch 1254/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 527857536.0000 - val_loss: 1706921984.0000\n",
      "Epoch 1255/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 523369696.0000 - val_loss: 1811909376.0000\n",
      "Epoch 1256/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 529020960.0000 - val_loss: 1879288192.0000\n",
      "Epoch 1257/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 524397952.0000 - val_loss: 1733345280.0000\n",
      "Epoch 1258/1500\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 521378528.0000 - val_loss: 1779697024.0000\n",
      "Epoch 1259/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 502714016.0000 - val_loss: 1642828416.0000\n",
      "Epoch 1260/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 514479712.0000 - val_loss: 1675303552.0000\n",
      "Epoch 1261/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 510459840.0000 - val_loss: 1661308288.0000\n",
      "Epoch 1262/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 520856864.0000 - val_loss: 1769685248.0000\n",
      "Epoch 1263/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 507731808.0000 - val_loss: 1723339904.0000\n",
      "Epoch 1264/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 513241856.0000 - val_loss: 1726174464.0000\n",
      "Epoch 1265/1500\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 524686112.0000 - val_loss: 1693042688.0000\n",
      "Epoch 1266/1500\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 502325568.0000 - val_loss: 1680290048.0000\n",
      "Epoch 1267/1500\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 509453216.0000 - val_loss: 1709204352.0000\n",
      "Epoch 1268/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 513003904.0000 - val_loss: 1705471488.0000\n",
      "Epoch 1269/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 523691648.0000 - val_loss: 1719710464.0000\n",
      "Epoch 1270/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 502648928.0000 - val_loss: 1660367744.0000\n",
      "Epoch 1271/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 524677888.0000 - val_loss: 1675943936.0000\n",
      "Epoch 1272/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 512993792.0000 - val_loss: 1686502912.0000\n",
      "Epoch 1273/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 508771072.0000 - val_loss: 1685701248.0000\n",
      "Epoch 1274/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 518688800.0000 - val_loss: 1680120448.0000\n",
      "Epoch 1275/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 506956384.0000 - val_loss: 1709316864.0000\n",
      "Epoch 1276/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 503376224.0000 - val_loss: 1711269504.0000\n",
      "Epoch 1277/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 503949952.0000 - val_loss: 1679774336.0000\n",
      "Epoch 1278/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 530241792.0000 - val_loss: 1696431616.0000\n",
      "Epoch 1279/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "117/117 [==============================] - 0s 1ms/step - loss: 497867104.0000 - val_loss: 1719374848.0000\n",
      "Epoch 1280/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 502277408.0000 - val_loss: 1682893952.0000\n",
      "Epoch 1281/1500\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 507414528.0000 - val_loss: 1659974016.0000\n",
      "Epoch 1282/1500\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 502105888.0000 - val_loss: 1751408128.0000\n",
      "Epoch 1283/1500\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 513497536.0000 - val_loss: 1636562688.0000\n",
      "Epoch 1284/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 495463968.0000 - val_loss: 1624264704.0000\n",
      "Epoch 1285/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 506240608.0000 - val_loss: 1787409792.0000\n",
      "Epoch 1286/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 506060576.0000 - val_loss: 1721313152.0000\n",
      "Epoch 1287/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 525827456.0000 - val_loss: 1628665344.0000\n",
      "Epoch 1288/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 508048256.0000 - val_loss: 1696765696.0000\n",
      "Epoch 1289/1500\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 505324448.0000 - val_loss: 1687665664.0000\n",
      "Epoch 1290/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 512510784.0000 - val_loss: 1702976768.0000\n",
      "Epoch 1291/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 512292896.0000 - val_loss: 1655508992.0000\n",
      "Epoch 1292/1500\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 506826048.0000 - val_loss: 1696594176.0000\n",
      "Epoch 1293/1500\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 499868224.0000 - val_loss: 1692752128.0000\n",
      "Epoch 1294/1500\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 509227072.0000 - val_loss: 1692717312.0000\n",
      "Epoch 1295/1500\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 514857216.0000 - val_loss: 1747337856.0000\n",
      "Epoch 1296/1500\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 498913280.0000 - val_loss: 1686464768.0000\n",
      "Epoch 1297/1500\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 509157280.0000 - val_loss: 1721276672.0000\n",
      "Epoch 1298/1500\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 497761696.0000 - val_loss: 1641715968.0000\n",
      "Epoch 1299/1500\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 506267680.0000 - val_loss: 1616212864.0000\n",
      "Epoch 1300/1500\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 510252736.0000 - val_loss: 1618091904.0000\n",
      "Epoch 1301/1500\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 495416896.0000 - val_loss: 1685503616.0000\n",
      "Epoch 1302/1500\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 498890176.0000 - val_loss: 1648349184.0000\n",
      "Epoch 1303/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 497191584.0000 - val_loss: 1589524224.0000\n",
      "Epoch 1304/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 497825504.0000 - val_loss: 1701446784.0000\n",
      "Epoch 1305/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 495530624.0000 - val_loss: 1652393088.0000\n",
      "Epoch 1306/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 501569408.0000 - val_loss: 1678233344.0000\n",
      "Epoch 1307/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 511242240.0000 - val_loss: 1653393664.0000\n",
      "Epoch 1308/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 506142048.0000 - val_loss: 1623422208.0000\n",
      "Epoch 1309/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 496070752.0000 - val_loss: 1684066304.0000\n",
      "Epoch 1310/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 518493216.0000 - val_loss: 1778246144.0000\n",
      "Epoch 1311/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 503771680.0000 - val_loss: 1675231104.0000\n",
      "Epoch 1312/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 501807008.0000 - val_loss: 1672968704.0000\n",
      "Epoch 1313/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 487123360.0000 - val_loss: 1711413632.0000\n",
      "Epoch 1314/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 493275040.0000 - val_loss: 1623461760.0000\n",
      "Epoch 1315/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 502670496.0000 - val_loss: 1599263360.0000\n",
      "Epoch 1316/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 498706720.0000 - val_loss: 1580551424.0000\n",
      "Epoch 1317/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 493242816.0000 - val_loss: 1658030592.0000\n",
      "Epoch 1318/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 487867744.0000 - val_loss: 1640315648.0000\n",
      "Epoch 1319/1500\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 501665664.0000 - val_loss: 1622268160.0000\n",
      "Epoch 1320/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 495929664.0000 - val_loss: 1640030720.0000\n",
      "Epoch 1321/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 492685056.0000 - val_loss: 1767137792.0000\n",
      "Epoch 1322/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 497841728.0000 - val_loss: 1713084928.0000\n",
      "Epoch 1323/1500\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 486965280.0000 - val_loss: 1632099584.0000\n",
      "Epoch 1324/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 497741376.0000 - val_loss: 1689689472.0000\n",
      "Epoch 1325/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 485563008.0000 - val_loss: 1632032896.0000\n",
      "Epoch 1326/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 491583136.0000 - val_loss: 1599893888.0000\n",
      "Epoch 1327/1500\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 491775296.0000 - val_loss: 1699660288.0000\n",
      "Epoch 1328/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 501847072.0000 - val_loss: 1682238080.0000\n",
      "Epoch 1329/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 488255008.0000 - val_loss: 1623551232.0000\n",
      "Epoch 1330/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 492827840.0000 - val_loss: 1633028352.0000\n",
      "Epoch 1331/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 492728288.0000 - val_loss: 1633512576.0000\n",
      "Epoch 1332/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 490141952.0000 - val_loss: 1568128512.0000\n",
      "Epoch 1333/1500\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 495781856.0000 - val_loss: 1615438464.0000\n",
      "Epoch 1334/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 502869312.0000 - val_loss: 1618824448.0000\n",
      "Epoch 1335/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 489692288.0000 - val_loss: 1658005760.0000\n",
      "Epoch 1336/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 479442400.0000 - val_loss: 1625245696.0000\n",
      "Epoch 1337/1500\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 481474400.0000 - val_loss: 1642609664.0000\n",
      "Epoch 1338/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 497255712.0000 - val_loss: 1629998464.0000\n",
      "Epoch 1339/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 483401728.0000 - val_loss: 1627060864.0000\n",
      "Epoch 1340/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 496984032.0000 - val_loss: 1668635136.0000\n",
      "Epoch 1341/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 477685056.0000 - val_loss: 1603517312.0000\n",
      "Epoch 1342/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 496751072.0000 - val_loss: 1682052736.0000\n",
      "Epoch 1343/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 482672992.0000 - val_loss: 1633544832.0000\n",
      "Epoch 1344/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 488244000.0000 - val_loss: 1639203328.0000\n",
      "Epoch 1345/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 485309632.0000 - val_loss: 1611407488.0000\n",
      "Epoch 1346/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "117/117 [==============================] - 0s 1ms/step - loss: 507178432.0000 - val_loss: 1649429248.0000\n",
      "Epoch 1347/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 477303072.0000 - val_loss: 1594827520.0000\n",
      "Epoch 1348/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 470244608.0000 - val_loss: 1660920064.0000\n",
      "Epoch 1349/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 485266240.0000 - val_loss: 1620955392.0000\n",
      "Epoch 1350/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 482194336.0000 - val_loss: 1597352192.0000\n",
      "Epoch 1351/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 472397088.0000 - val_loss: 1573645440.0000\n",
      "Epoch 1352/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 482248320.0000 - val_loss: 1600138496.0000\n",
      "Epoch 1353/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 490195680.0000 - val_loss: 1609971712.0000\n",
      "Epoch 1354/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 481697024.0000 - val_loss: 1689073536.0000\n",
      "Epoch 1355/1500\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 489626208.0000 - val_loss: 1621104384.0000\n",
      "Epoch 1356/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 488120768.0000 - val_loss: 1577623296.0000\n",
      "Epoch 1357/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 486494112.0000 - val_loss: 1591425920.0000\n",
      "Epoch 1358/1500\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 484045568.0000 - val_loss: 1554455168.0000\n",
      "Epoch 1359/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 480421344.0000 - val_loss: 1579934464.0000\n",
      "Epoch 1360/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 484188160.0000 - val_loss: 1526791424.0000\n",
      "Epoch 1361/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 483205696.0000 - val_loss: 1645090688.0000\n",
      "Epoch 1362/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 482985088.0000 - val_loss: 1700616832.0000\n",
      "Epoch 1363/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 481256800.0000 - val_loss: 1611291392.0000\n",
      "Epoch 1364/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 473544768.0000 - val_loss: 1592272256.0000\n",
      "Epoch 1365/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 481114144.0000 - val_loss: 1541277824.0000\n",
      "Epoch 1366/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 493963936.0000 - val_loss: 1582390272.0000\n",
      "Epoch 1367/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 490905632.0000 - val_loss: 1634081280.0000\n",
      "Epoch 1368/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 495165984.0000 - val_loss: 1607222144.0000\n",
      "Epoch 1369/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 489648896.0000 - val_loss: 1576486912.0000\n",
      "Epoch 1370/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 485736896.0000 - val_loss: 1585840384.0000\n",
      "Epoch 1371/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 480636704.0000 - val_loss: 1624524672.0000\n",
      "Epoch 1372/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 487404544.0000 - val_loss: 1566608128.0000\n",
      "Epoch 1373/1500\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 480823136.0000 - val_loss: 1558781440.0000\n",
      "Epoch 1374/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 478894080.0000 - val_loss: 1656142976.0000\n",
      "Epoch 1375/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 477697024.0000 - val_loss: 1611912704.0000\n",
      "Epoch 1376/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 479756032.0000 - val_loss: 1640604928.0000\n",
      "Epoch 1377/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 474370304.0000 - val_loss: 1627400704.0000\n",
      "Epoch 1378/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 487048288.0000 - val_loss: 1607652608.0000\n",
      "Epoch 1379/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 464389184.0000 - val_loss: 1606595456.0000\n",
      "Epoch 1380/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 465204992.0000 - val_loss: 1625285504.0000\n",
      "Epoch 1381/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 476798048.0000 - val_loss: 1595907328.0000\n",
      "Epoch 1382/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 477452064.0000 - val_loss: 1617750400.0000\n",
      "Epoch 1383/1500\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 470264928.0000 - val_loss: 1627826688.0000\n",
      "Epoch 1384/1500\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 496988352.0000 - val_loss: 1657790336.0000\n",
      "Epoch 1385/1500\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 476790784.0000 - val_loss: 1595334528.0000\n",
      "Epoch 1386/1500\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 491011776.0000 - val_loss: 1573895168.0000\n",
      "Epoch 1387/1500\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 461478496.0000 - val_loss: 1594212480.0000\n",
      "Epoch 1388/1500\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 498753952.0000 - val_loss: 1644895360.0000\n",
      "Epoch 1389/1500\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 473719872.0000 - val_loss: 1602678912.0000\n",
      "Epoch 1390/1500\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 480940160.0000 - val_loss: 1645615744.0000\n",
      "Epoch 1391/1500\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 474897664.0000 - val_loss: 1594202752.0000\n",
      "Epoch 1392/1500\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 487278976.0000 - val_loss: 1553115520.0000\n",
      "Epoch 1393/1500\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 478823072.0000 - val_loss: 1560292480.0000\n",
      "Epoch 1394/1500\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 484660896.0000 - val_loss: 1675687680.0000\n",
      "Epoch 1395/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 481783616.0000 - val_loss: 1559561600.0000\n",
      "Epoch 1396/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 465429120.0000 - val_loss: 1566721024.0000\n",
      "Epoch 1397/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 464657888.0000 - val_loss: 1502171904.0000\n",
      "Epoch 1398/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 482802912.0000 - val_loss: 1563675392.0000\n",
      "Epoch 1399/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 469819104.0000 - val_loss: 1539192448.0000\n",
      "Epoch 1400/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 479837120.0000 - val_loss: 1697607168.0000\n",
      "Epoch 1401/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 478129024.0000 - val_loss: 1554361472.0000\n",
      "Epoch 1402/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 474483520.0000 - val_loss: 1566980864.0000\n",
      "Epoch 1403/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 474153248.0000 - val_loss: 1665700864.0000\n",
      "Epoch 1404/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 478445664.0000 - val_loss: 1586905856.0000\n",
      "Epoch 1405/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 476608672.0000 - val_loss: 1562900608.0000\n",
      "Epoch 1406/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 462956640.0000 - val_loss: 1620466944.0000\n",
      "Epoch 1407/1500\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 474620064.0000 - val_loss: 1602140160.0000\n",
      "Epoch 1408/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 469904384.0000 - val_loss: 1544274816.0000\n",
      "Epoch 1409/1500\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 470975712.0000 - val_loss: 1573865600.0000\n",
      "Epoch 1410/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 461610944.0000 - val_loss: 1600851712.0000\n",
      "Epoch 1411/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 480385792.0000 - val_loss: 1593472384.0000\n",
      "Epoch 1412/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 470341920.0000 - val_loss: 1550118400.0000\n",
      "Epoch 1413/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "117/117 [==============================] - 0s 1ms/step - loss: 469194016.0000 - val_loss: 1684815744.0000\n",
      "Epoch 1414/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 470163392.0000 - val_loss: 1561710080.0000\n",
      "Epoch 1415/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 468504768.0000 - val_loss: 1617973888.0000\n",
      "Epoch 1416/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 491700544.0000 - val_loss: 1608881408.0000\n",
      "Epoch 1417/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 462030912.0000 - val_loss: 1624523648.0000\n",
      "Epoch 1418/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 460857088.0000 - val_loss: 1508412544.0000\n",
      "Epoch 1419/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 456597088.0000 - val_loss: 1569011200.0000\n",
      "Epoch 1420/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 467260224.0000 - val_loss: 1541752832.0000\n",
      "Epoch 1421/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 459703488.0000 - val_loss: 1632996224.0000\n",
      "Epoch 1422/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 471048672.0000 - val_loss: 1548451968.0000\n",
      "Epoch 1423/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 450689920.0000 - val_loss: 1583579136.0000\n",
      "Epoch 1424/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 474084000.0000 - val_loss: 1513510144.0000\n",
      "Epoch 1425/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 458738528.0000 - val_loss: 1563252352.0000\n",
      "Epoch 1426/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 467239488.0000 - val_loss: 1571734400.0000\n",
      "Epoch 1427/1500\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 470543552.0000 - val_loss: 1537318144.0000\n",
      "Epoch 1428/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 477990944.0000 - val_loss: 1569530112.0000\n",
      "Epoch 1429/1500\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 467000544.0000 - val_loss: 1631730560.0000\n",
      "Epoch 1430/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 460476608.0000 - val_loss: 1599868032.0000\n",
      "Epoch 1431/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 471667712.0000 - val_loss: 1511515904.0000\n",
      "Epoch 1432/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 467293408.0000 - val_loss: 1540864384.0000\n",
      "Epoch 1433/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 460989856.0000 - val_loss: 1627957376.0000\n",
      "Epoch 1434/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 458280800.0000 - val_loss: 1526603904.0000\n",
      "Epoch 1435/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 457191072.0000 - val_loss: 1526567296.0000\n",
      "Epoch 1436/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 479678816.0000 - val_loss: 1520219520.0000\n",
      "Epoch 1437/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 454769760.0000 - val_loss: 1557068672.0000\n",
      "Epoch 1438/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 478063712.0000 - val_loss: 1523626240.0000\n",
      "Epoch 1439/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 459991232.0000 - val_loss: 1577479296.0000\n",
      "Epoch 1440/1500\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 451542848.0000 - val_loss: 1502113664.0000\n",
      "Epoch 1441/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 475977472.0000 - val_loss: 1549106944.0000\n",
      "Epoch 1442/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 462865952.0000 - val_loss: 1605570432.0000\n",
      "Epoch 1443/1500\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 478335360.0000 - val_loss: 1592725504.0000\n",
      "Epoch 1444/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 466403392.0000 - val_loss: 1580237184.0000\n",
      "Epoch 1445/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 466757152.0000 - val_loss: 1552730752.0000\n",
      "Epoch 1446/1500\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 464282848.0000 - val_loss: 1580976512.0000\n",
      "Epoch 1447/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 471861824.0000 - val_loss: 1603068160.0000\n",
      "Epoch 1448/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 460974624.0000 - val_loss: 1577040384.0000\n",
      "Epoch 1449/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 480969888.0000 - val_loss: 1525183872.0000\n",
      "Epoch 1450/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 462770880.0000 - val_loss: 1517727104.0000\n",
      "Epoch 1451/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 474600384.0000 - val_loss: 1571596160.0000\n",
      "Epoch 1452/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 459407104.0000 - val_loss: 1555637120.0000\n",
      "Epoch 1453/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 451211648.0000 - val_loss: 1585063552.0000\n",
      "Epoch 1454/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 454858400.0000 - val_loss: 1589084288.0000\n",
      "Epoch 1455/1500\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 469955776.0000 - val_loss: 1562888832.0000\n",
      "Epoch 1456/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 449220928.0000 - val_loss: 1518867072.0000\n",
      "Epoch 1457/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 455074080.0000 - val_loss: 1535207296.0000\n",
      "Epoch 1458/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 451526912.0000 - val_loss: 1560275456.0000\n",
      "Epoch 1459/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 471202784.0000 - val_loss: 1658963328.0000\n",
      "Epoch 1460/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 460225056.0000 - val_loss: 1546248576.0000\n",
      "Epoch 1461/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 465679360.0000 - val_loss: 1593961856.0000\n",
      "Epoch 1462/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 458193120.0000 - val_loss: 1533447680.0000\n",
      "Epoch 1463/1500\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 457548608.0000 - val_loss: 1513277184.0000\n",
      "Epoch 1464/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 449157760.0000 - val_loss: 1540749440.0000\n",
      "Epoch 1465/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 464682048.0000 - val_loss: 1531872768.0000\n",
      "Epoch 1466/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 459977344.0000 - val_loss: 1536482304.0000\n",
      "Epoch 1467/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 454549504.0000 - val_loss: 1526701312.0000\n",
      "Epoch 1468/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 454569600.0000 - val_loss: 1511403904.0000\n",
      "Epoch 1469/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 453194688.0000 - val_loss: 1516659968.0000\n",
      "Epoch 1470/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 455946432.0000 - val_loss: 1596043264.0000\n",
      "Epoch 1471/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 463674496.0000 - val_loss: 1517072256.0000\n",
      "Epoch 1472/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 470672128.0000 - val_loss: 1508946560.0000\n",
      "Epoch 1473/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 479714880.0000 - val_loss: 1527236480.0000\n",
      "Epoch 1474/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 458911104.0000 - val_loss: 1567540224.0000\n",
      "Epoch 1475/1500\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 457556896.0000 - val_loss: 1527142784.0000\n",
      "Epoch 1476/1500\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 458463424.0000 - val_loss: 1562767104.0000\n",
      "Epoch 1477/1500\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 479189568.0000 - val_loss: 1501531264.0000\n",
      "Epoch 1478/1500\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 454277440.0000 - val_loss: 1554644224.0000\n",
      "Epoch 1479/1500\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 447850848.0000 - val_loss: 1507418368.0000\n",
      "Epoch 1480/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "117/117 [==============================] - 0s 2ms/step - loss: 448145056.0000 - val_loss: 1550873856.0000\n",
      "Epoch 1481/1500\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 446934528.0000 - val_loss: 1560310656.0000\n",
      "Epoch 1482/1500\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 447866048.0000 - val_loss: 1508558464.0000\n",
      "Epoch 1483/1500\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 468061344.0000 - val_loss: 1504316544.0000\n",
      "Epoch 1484/1500\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 461949888.0000 - val_loss: 1507946368.0000\n",
      "Epoch 1485/1500\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 458068096.0000 - val_loss: 1536460288.0000\n",
      "Epoch 1486/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 468945696.0000 - val_loss: 1508769280.0000\n",
      "Epoch 1487/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 474602656.0000 - val_loss: 1478513152.0000\n",
      "Epoch 1488/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 455910528.0000 - val_loss: 1522930560.0000\n",
      "Epoch 1489/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 454760064.0000 - val_loss: 1501572736.0000\n",
      "Epoch 1490/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 437790848.0000 - val_loss: 1506394368.0000\n",
      "Epoch 1491/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 458405440.0000 - val_loss: 1506380544.0000\n",
      "Epoch 1492/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 468021920.0000 - val_loss: 1575752576.0000\n",
      "Epoch 1493/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 461243104.0000 - val_loss: 1539348224.0000\n",
      "Epoch 1494/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 443810112.0000 - val_loss: 1490667136.0000\n",
      "Epoch 1495/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 457500064.0000 - val_loss: 1510522496.0000\n",
      "Epoch 1496/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 453773984.0000 - val_loss: 1486613504.0000\n",
      "Epoch 1497/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 452354496.0000 - val_loss: 1566200064.0000\n",
      "Epoch 1498/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 448445664.0000 - val_loss: 1503601152.0000\n",
      "Epoch 1499/1500\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 456870592.0000 - val_loss: 1489641344.0000\n",
      "Epoch 1500/1500\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 454094496.0000 - val_loss: 1483916160.0000\n"
     ]
    }
   ],
   "source": [
    "# Initialising the ANN\n",
    "classifier = Sequential()\n",
    "\n",
    "# Adding the input layer and the first hidden layer\n",
    "classifier.add(Dense(units = 64,activation='relu'))\n",
    "\n",
    "# Adding the second hidden layer\n",
    "classifier.add(Dense(units = 32,activation='relu'))\n",
    "\n",
    "# Adding the third hidden layer\n",
    "classifier.add(Dense(units = 16,activation='relu'))\n",
    "# Adding the output layer\n",
    "classifier.add(Dense(units = 1))\n",
    "\n",
    "# Compiling the ANN\n",
    "classifier.compile(loss='mean_squared_error', optimizer='AdamaX')\n",
    "\n",
    "# Fitting the ANN to the Training set\n",
    "model_history=classifier.fit(x_train.values, y_train.values,validation_split=0.20, batch_size = 10, epochs = 1500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "cf749d08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46/46 [==============================] - 0s 897us/step\n"
     ]
    }
   ],
   "source": [
    "pred2=classifier.predict((df_Test).values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "9d4160d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_=pd.DataFrame(pred2)\n",
    "sub_df=pd.read_csv('sample_submission.csv')\n",
    "datasets_=pd.concat([sub_df['Id'],pred_],axis=1)\n",
    "datasets_.columns=['Id','SalePrice']\n",
    "datasets_.to_csv('sample_submission3.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b133f45d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
